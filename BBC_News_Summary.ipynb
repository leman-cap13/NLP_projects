{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOmSn4e9dQyfV142htyMgid",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leman-cap13/my_projects/blob/main/BBC_News_Summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "V4epAFJ05ipa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neHNXzK73OB0"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "IjrvS12c3XxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download pariza/bbc-news-summary"
      ],
      "metadata": {
        "id": "P0E-2d2E3ZUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile"
      ],
      "metadata": {
        "id": "nnJnolkM3hRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('/content/bbc-news-summary.zip','r') as zip_ref:\n",
        "  zip_ref.extractall()"
      ],
      "metadata": {
        "id": "ydYGNl7m3jsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "S3TInhaS3tF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_path = '/content/BBC News Summary/News Articles'\n",
        "file_list = os.listdir(folder_path)\n",
        "\n",
        "print(file_list)"
      ],
      "metadata": {
        "id": "WM4DUssF4oBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_path = '/content/BBC News Summary/Summaries'\n",
        "file_list = os.listdir(folder_path)\n",
        "\n",
        "print(file_list)\n"
      ],
      "metadata": {
        "id": "8b_NwGHT4r6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "base_path = '/content/BBC News Summary/News Articles'\n",
        "categories = ['sport', 'business', 'tech', 'politics', 'entertainment']\n",
        "\n",
        "data = []\n",
        "\n",
        "for category in categories:\n",
        "    folder_path = os.path.join(base_path, category)\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "\n",
        "            content = file.read()\n",
        "            data.append({\n",
        "                'category': category,\n",
        "                'content': content\n",
        "            })\n",
        "\n",
        "df = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "Dqun2SID46PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "_hK5Q6DH5HwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "print(df['category'].value_counts())\n"
      ],
      "metadata": {
        "id": "V5qks0Xh5Tk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/BBC News Summary/Summaries'\n",
        "categories = ['sport', 'business', 'tech', 'politics', 'entertainment']\n",
        "\n",
        "data = []\n",
        "\n",
        "for category in categories:\n",
        "    folder_path = os.path.join(base_path, category)\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "\n",
        "            content = file.read()\n",
        "            data.append({\n",
        "                'category': category,\n",
        "                'content': content\n",
        "            })\n",
        "\n",
        "df_sum = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "4nS3T4nP5YeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sum"
      ],
      "metadata": {
        "id": "8AC2F1A15dyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sum['category'].value_counts()"
      ],
      "metadata": {
        "id": "0lkz-qoU5pat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Articles\n",
        "articles = []\n",
        "\n",
        "for category in categories:\n",
        "    folder_path = os.path.join('/content/BBC News Summary/News Articles', category)\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "            content = file.read()\n",
        "            articles.append({\n",
        "                'filename': filename,\n",
        "                'category': category,\n",
        "                'content': content\n",
        "            })\n",
        "\n",
        "df_articles = pd.DataFrame(articles)\n",
        "\n",
        "# Loading Summaries\n",
        "summaries = []\n",
        "\n",
        "for category in categories:\n",
        "    folder_path = os.path.join('/content/BBC News Summary/Summaries', category)\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "            summary = file.read()\n",
        "            summaries.append({\n",
        "                'filename': filename,\n",
        "                'category': category,\n",
        "                'summary': summary\n",
        "            })\n",
        "\n",
        "df_summaries = pd.DataFrame(summaries)\n",
        "\n",
        "# Merge on filename and category\n",
        "df_full = pd.merge(df_articles, df_summaries, on=['filename', 'category'])\n"
      ],
      "metadata": {
        "id": "_8s9eY5f6Pt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_full.drop('filename',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "WCuija7J6Tha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_full"
      ],
      "metadata": {
        "id": "NBJ7pG5i6mHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning"
      ],
      "metadata": {
        "id": "XNYCMyxl6uC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will perform these cleaning steps:\n",
        "\n",
        "Lowercasing\n",
        "\n",
        "Removing punctuation\n",
        "\n",
        "Removing numbers\n",
        "\n",
        "Removing stopwords\n",
        "\n",
        "Tokenization\n",
        "\n",
        "Lemmatization"
      ],
      "metadata": {
        "id": "-HynMXKb7y5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "XFazFfFy6uAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords') #for text summarization tasks, removing stopwords is NOT a good idea.\n",
        "nltk.download('punkt')     # For text summarization task, removion punnk is not good idea\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "1kS_O4yw6t93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "punkt is a pre-trained sentence tokenizer. It helps NLTK split text into sentences and words\n",
        "\n",
        "nltk.download('stopwords')\n",
        "Downloads a list of common English stopwords (like \"the\", \"is\", \"and\", etc.).\n",
        "\n",
        "WordNet is a lexical database of English. It contains meanings (synsets), relationships, and morphological info of words."
      ],
      "metadata": {
        "id": "cOQOwbEo8OCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "UvoIQxNW8zEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_full['clean_content'] = df_full['content'].apply(preprocess_text)\n",
        "df_full['clean_summary'] = df_full['summary'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "c5csMh_-9u-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_full.drop(['content','summary'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "kwiUeGvZ96Rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_full['clean_content'][0]"
      ],
      "metadata": {
        "id": "4wFoPaJn95-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_full['clean_summary'][0]"
      ],
      "metadata": {
        "id": "n3r_hpCS-jzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "85WmvEMX-pNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plan\n",
        "#1.AutoTokenizer\n",
        "#2.Dataloader TensorDataset\n",
        "#3.Loss optimizer accelerator\n",
        "#4.Custom training loop\n",
        "#5.model generate"
      ],
      "metadata": {
        "id": "L-gf6f8P-pGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(df_full, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "d57eUJeu7SD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.Tokenization"
      ],
      "metadata": {
        "id": "obmf7NQk4fjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"google/pegasus-cnn_dailymail\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "WhFFR1_Sc6ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs = list(train_df['clean_content'])   # No prefix!\n",
        "train_targets = list(train_df['clean_summary'])  # This stays the same\n",
        "\n"
      ],
      "metadata": {
        "id": "H3UgxO5o4KuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That \"summarize: \" prefix is specific to T5, because T5 is trained as a general-purpose text-to-text transformer, and it uses task-specific prefixes like \"translate English to German:\", \"summarize:\", etc.\n",
        "\n",
        " For Pegasus, you should remove the \"summarize: \" prefix:"
      ],
      "metadata": {
        "id": "K44yPGBs4RfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For T5, you need to prefix your input with \"summarize:\n",
        "# train_inputs = [\"summarize: \" + text for text in train_df['clean_content']]\n",
        "# train_targets = list(train_df['clean_summary'])\n"
      ],
      "metadata": {
        "id": "5ubikIgz1j_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs[0]"
      ],
      "metadata": {
        "id": "AnDPirhD15EC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_targets[0]"
      ],
      "metadata": {
        "id": "KVREIyMF17bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EzatCS1g7fed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_tokenized = tokenizer(\n",
        "    train_inputs,\n",
        "    max_length=256,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    return_tensors='pt')\n",
        "\n",
        "targets_tokenized = tokenizer(\n",
        "    train_targets,\n",
        "    max_length=128,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    return_tensors='pt')"
      ],
      "metadata": {
        "id": "jtfCN3b618yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_tokenized['input_ids']"
      ],
      "metadata": {
        "id": "KT1B4Qjj2Wa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_tokenized['attention_mask']"
      ],
      "metadata": {
        "id": "oLve9Ubz2iQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets_tokenized['input_ids']"
      ],
      "metadata": {
        "id": "YL_tSaEN2mEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#T5 expects padding tokens in labels to be -100 so that they‚Äôre ignored in loss calculation.\n",
        "\n",
        "labels = targets_tokenized['input_ids']\n",
        "labels[labels == tokenizer.pad_token_id] = -100"
      ],
      "metadata": {
        "id": "KRgfvbHZ2oHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_inputs = list(val_df['clean_content'])\n",
        "val_targets = list(val_df['clean_summary'])\n",
        "\n",
        "val_inputs_tokenized = tokenizer(\n",
        "    val_inputs,\n",
        "    max_length=256,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    return_tensors='pt')\n",
        "\n",
        "val_targets_tokenized = tokenizer(\n",
        "    val_targets,\n",
        "    max_length=128,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    return_tensors='pt')\n",
        "\n",
        "val_labels = val_targets_tokenized['input_ids']\n",
        "val_labels[val_labels == tokenizer.pad_token_id] = -100\n"
      ],
      "metadata": {
        "id": "2yvvG0Wv7oyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.DataLoader with TensorDataset"
      ],
      "metadata": {
        "id": "kZdWeHSA20vG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_dataset = TensorDataset(\n",
        "    inputs_tokenized['input_ids'],\n",
        "    inputs_tokenized['attention_mask'],\n",
        "    labels\n",
        ")\n",
        "\n",
        "val_dataset = TensorDataset(\n",
        "    val_inputs_tokenized['input_ids'],\n",
        "    val_inputs_tokenized['attention_mask'],\n",
        "    val_labels\n",
        ")\n"
      ],
      "metadata": {
        "id": "G-ZZCn_x2-Ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "I1tSqHhj43zB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True)\n",
        "\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)"
      ],
      "metadata": {
        "id": "eX0CayFy5Qip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader"
      ],
      "metadata": {
        "id": "FGuWDmMB5VWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_loader:\n",
        "    input_ids, attention_mask, labels = batch\n",
        "    print(input_ids.shape, attention_mask.shape, labels.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "_06PM5XLC0my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model, Optimizer, Accelerator"
      ],
      "metadata": {
        "id": "1f4DycX_4ZG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/pegasus-cnn_dailymail\")"
      ],
      "metadata": {
        "id": "mmRgkaZrDJpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "lNAnb3VVEDph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator\n",
        "\n",
        "accelerator = Accelerator()\n",
        "model, optimizer, train_loader, val_loader = accelerator.prepare(\n",
        "    model, optimizer, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "XqRhsbL0EK7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_loader)\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "        accelerator.backward(loss)\n",
        "\n",
        "        # Optional: Gradient clipping for stability\n",
        "        clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "            loss = outputs.loss\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n"
      ],
      "metadata": {
        "id": "KENHUUfZFUEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seaborn"
      ],
      "metadata": {
        "id": "LMsAjxO2HwNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Create x-axis labels for epochs\n",
        "epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "# Plot losses\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, train_losses, label='Training Loss', marker='o')\n",
        "plt.plot(epochs, val_losses, label='Validation Loss', marker='s')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "j86xrjNzFhOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate  model with .generate()"
      ],
      "metadata": {
        "id": "8oW2-YGdF7Xp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate summaries from your fine-tuned model\n",
        "\n",
        "Compare them to reference summaries\n",
        "\n",
        "Optionally: Evaluate with metrics like ROUGE"
      ],
      "metadata": {
        "id": "Q4VdC5v-GAjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import textwrap\n",
        "\n",
        "model.eval()\n",
        "n_samples = 5  # number of samples to generate\n",
        "\n",
        "for i in range(n_samples):\n",
        "    input_text = val_df['clean_content'].iloc[i]\n",
        "    reference_summary = val_df['clean_summary'].iloc[i]\n",
        "\n",
        "    input_ids = tokenizer(\n",
        "        input_text,\n",
        "        return_tensors='pt',\n",
        "        max_length=512,\n",
        "        truncation=True,\n",
        "        padding='max_length'\n",
        "    ).input_ids.to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            max_length=128,\n",
        "            do_sample=True,        # enable sampling\n",
        "            num_beams=4,           # beam search with 4 beams\n",
        "            top_k=50,              # top-k sampling\n",
        "            top_p=0.95,            # nucleus sampling\n",
        "            temperature=0.9,       # temperature for randomness\n",
        "            early_stopping=True\n",
        "        )\n",
        "        generated_summary = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    print(\"=\" * 100)\n",
        "    print(f\"\\nüì∞ ORIGINAL ARTICLE:\\n{textwrap.fill(input_text[:300], width=100)}...\")\n",
        "    print(f\"\\n‚úÖ REFERENCE SUMMARY:\\n{textwrap.fill(reference_summary, width=100)}\")\n",
        "    print(f\"\\nüîÅ GENERATED SUMMARY (sampled beam search):\\n{textwrap.fill(generated_summary, width=100)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "FRUWACozGCYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ROUGE evaluation"
      ],
      "metadata": {
        "id": "MEYN__SCIiUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score"
      ],
      "metadata": {
        "id": "P7aFJVc6GCVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "generated_summaries = []\n",
        "reference_summaries = []\n",
        "\n",
        "model.eval()\n",
        "n_samples = 5  # or change as needed\n",
        "\n",
        "for i in range(n_samples):\n",
        "    input_text = val_df['clean_content'].iloc[i]\n",
        "    reference_summary = val_df['clean_summary'].iloc[i]\n",
        "\n",
        "    input_ids = tokenizer(\n",
        "        input_text,\n",
        "        return_tensors='pt',\n",
        "        max_length=512,\n",
        "        truncation=True,\n",
        "        padding='max_length'\n",
        "    ).input_ids.to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            max_length=128,\n",
        "            do_sample=True,\n",
        "            num_beams=4,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            temperature=0.9,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        generated_summary = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    generated_summaries.append(generated_summary)\n",
        "    reference_summaries.append(reference_summary)\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "rouge1_scores = []\n",
        "rouge2_scores = []\n",
        "rougeL_scores = []\n",
        "\n",
        "for ref, gen in zip(reference_summaries, generated_summaries):\n",
        "    scores = scorer.score(ref, gen)\n",
        "    rouge1_scores.append(scores['rouge1'].fmeasure)\n",
        "    rouge2_scores.append(scores['rouge2'].fmeasure)\n",
        "    rougeL_scores.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "print(f\"Average ROUGE-1 F1 Score: {sum(rouge1_scores)/len(rouge1_scores):.4f}\")\n",
        "print(f\"Average ROUGE-2 F1 Score: {sum(rouge2_scores)/len(rouge2_scores):.4f}\")\n",
        "print(f\"Average ROUGE-L F1 Score: {sum(rougeL_scores)/len(rougeL_scores):.4f}\")\n"
      ],
      "metadata": {
        "id": "QO9uqdTMIjnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Your 0.67 ROUGE-1 is very good\n",
        "‚úÖ Your 0.59 ROUGE-2 is excellent\n",
        "‚úÖ Your 0.46 ROUGE-L is solid\n",
        "\n",
        "So don‚Äôt chase 1.0 ‚Äî it‚Äôs not realistic or necessary. Instead, if you want to go further:\n",
        "\n",
        "Compare against human summaries.\n",
        "\n",
        "Try BLEU, METEOR, or even BERTScore for deeper semantic comparison.\n",
        "\n",
        "Perform qualitative evaluation: are your summaries coherent, concise, and factual?"
      ],
      "metadata": {
        "id": "VoFArCG_FXSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"In a surprising turn of events, the government announced a new initiative aimed at tackling climate change by investing over $10 billion into renewable energy projects across the country. The plan includes the construction of wind farms, solar power stations, and funding for research into energy storage technologies. Experts believe this move could significantly reduce the nation‚Äôs carbon footprint over the next decade, although some critics argue that the plan lacks clear short-term implementation goals. Nevertheless, the announcement has been met with cautious optimism from environmental groups and industry leaders alike.\"\n",
        "input_ids = tokenizer(\n",
        "    input_text,\n",
        "    return_tensors='pt',\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    max_length=512).input_ids.to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    summary_ids = model.generate(input_ids, max_length=100, num_beams=4, early_stopping=True)\n",
        "\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(summary)\n"
      ],
      "metadata": {
        "id": "NZG9hIU6FZIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "print(textwrap.fill(summary, width=100))\n"
      ],
      "metadata": {
        "id": "G8uaSBGPG3Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gen_lengths = [len(s.split()) for s in generated_summaries]\n",
        "ref_lengths = [len(s.split()) for s in reference_summaries]\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.hist(gen_lengths, bins=10, alpha=0.7, label='Generated')\n",
        "plt.hist(ref_lengths, bins=10, alpha=0.7, label='Reference')\n",
        "plt.xlabel('Number of Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Summary Lengths')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "COzSkZbeKctw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_len = min(len(val_df['clean_content']), len(reference_summaries), len(generated_summaries))\n",
        "print(\"Minimum length:\", min_len)\n",
        "\n",
        "df_eval = pd.DataFrame({\n",
        "    \"Original Text\": val_df['clean_content'][:min_len].values,\n",
        "    \"Reference Summary\": reference_summaries[:min_len],\n",
        "    \"Generated Summary\": generated_summaries[:min_len]\n",
        "})\n",
        "\n",
        "\n",
        "df_eval['input_len'] = df_eval['Original Text'].apply(lambda x: len(x.split()))\n",
        "df_eval['gen_len'] = df_eval['Generated Summary'].apply(lambda x: len(x.split()))\n",
        "df_eval['ref_len'] = df_eval['Reference Summary'].apply(lambda x: len(x.split()))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='input_len', y='gen_len', data=df_eval, label='Generated')\n",
        "sns.scatterplot(x='input_len', y='ref_len', data=df_eval, label='Reference')\n",
        "plt.xlabel(\"Input Length (words)\")\n",
        "plt.ylabel(\"Summary Length (words)\")\n",
        "plt.title(\"Input vs Summary Length\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GyAjBSrvKjvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DTwbyaUcKjsf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}