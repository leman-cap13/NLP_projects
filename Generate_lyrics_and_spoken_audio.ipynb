{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOXKlnEmbcvHFMab22Y62Vz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leman-cap13/my_projects/blob/main/Generate_lyrics_and_spoken_audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "ulDuDw-socRq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9qQ71mak5ps"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install TTS\n",
        "!pip install torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "transformers: For GPT-2 (lyrics generation)\n",
        "\n",
        "TTS: From Coqui (text-to-speech synthesis)\n",
        "\n",
        "torchaudio: To play audio in Colab\n",
        "\n"
      ],
      "metadata": {
        "id": "lTX8YtbklVrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install gpt 2 for lyrics generating\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "\n",
        "model_name = \"google/flan-t5-base\"\n",
        "# model_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "H2FlNYUEk7rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is GPT2LMHeadModel?\n",
        "Itâ€™s the GPT-2 architecture model with a language modeling (LM) head on top.\n",
        "\n",
        "The LM head is specifically designed for generating text by predicting the next token in a sequence.\n",
        "\n",
        "This model is pre-trained on large amounts of text data to learn how to produce coherent, fluent language when given a prompt."
      ],
      "metadata": {
        "id": "3J2TC8Hlmc3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why use GPT2LMHeadModel for your lyrics generation?\n",
        "Text Generation Focus:\n",
        "The LM head enables the model to predict next words, so it can generate new text (lyrics) from a starting prompt.\n",
        "\n",
        "Pretrained, Large-Scale:\n",
        "GPT-2 is trained on diverse internet text, including creative writing styles, so it can generate song-like language even without fine-tuning.\n",
        "\n",
        "Easy to Use:\n",
        "Hugging Face provides this model ready for generation tasks â€” no extra modification needed.\n",
        "\n",
        "Control:\n",
        "You can control generation parameters (temperature, top-k, top-p) for creative or conservative outputs."
      ],
      "metadata": {
        "id": "fR5I0ST2mpkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Write a romantic pop song about heartbreak. Make it emotional and poetic.\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "min_lines = 10\n",
        "max_tries = 5\n",
        "lyrics = \"\"\n",
        "\n",
        "for attempt in range(max_tries):\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_length=250,\n",
        "        min_length=100,  # â¬…ï¸ force longer outputs\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        no_repeat_ngram_size=3\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "jhA84YO-mH28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "max_length=100: generate up to 100 tokens (including the prompt tokens).\n",
        "\n",
        "do_sample=True: use sampling instead of greedy decoding, allowing for creative, varied outputs.\n",
        "\n",
        "temperature=0.8: controls randomness â€” lower is more conservative, higher is more creative.\n",
        "\n"
      ],
      "metadata": {
        "id": "LiIp7sqln6qQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generated = tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "FqIQTLneFOLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract generated lyrics\n",
        "# lyrics = generated[len(prompt):].strip()\n",
        "lyrics = generated.strip()\n",
        "print(\"ðŸŽ¤ Generated Lyrics:\\n\", lyrics)"
      ],
      "metadata": {
        "id": "SpzcTLcCmHzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.api import TTS\n",
        "\n",
        "# Load Coqui TTS model (lightweight, CPU-friendly)\n",
        "tts = TTS(model_name=\"tts_models/en/ljspeech/tacotron2-DDC\", progress_bar=False, gpu=False)\n",
        "\n",
        "# Save spoken audio to file\n",
        "tts.tts_to_file(text=lyrics, file_path=\"lyrics.wav\")\n"
      ],
      "metadata": {
        "id": "RBm4rARpoLIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd\n",
        "\n",
        "# Play the audio file\n",
        "ipd.Audio(\"lyrics.wav\")\n"
      ],
      "metadata": {
        "id": "PYoil-WEoQ4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine Tuned model"
      ],
      "metadata": {
        "id": "PJGiQyJSOWfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install transformers datasets"
      ],
      "metadata": {
        "id": "xBHi8aQBRQVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "import torch"
      ],
      "metadata": {
        "id": "t9t-2FjDRX8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "5hOJe-b5SI-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "wrMiJhTCSPFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d deepshah16/song-lyrics-dataset"
      ],
      "metadata": {
        "id": "dtGgb0wtSRRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/song-lyrics-dataset.zip', 'r')\n",
        "zip_ref.extractall()"
      ],
      "metadata": {
        "id": "-Q-3CHrUSROO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load your lyrics CSV file (upload lyrics.csv in Colab)\n",
        "df = pd.read_csv(\"/content/csv/BillieEilish.csv\")\n",
        "df== df.dropna(subset=[\"Lyric\"])  # Drop rows without lyrics\n",
        "df"
      ],
      "metadata": {
        "id": "hqVL41BfRdNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Convert to HuggingFace Dataset and split\n",
        "dataset = Dataset.from_pandas(df)\n",
        "dataset = dataset.train_test_split(test_size=0.1)"
      ],
      "metadata": {
        "id": "8RQjr5UdTEZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dataset split: {dataset}\")"
      ],
      "metadata": {
        "id": "Q_WkjL3NTISy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Load tokenizer and set pad token\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
        "tokenizer.pad_token = tokenizer.eos_token  # GPT2 does not have a pad token by default"
      ],
      "metadata": {
        "id": "UuhwaMWETNeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Tokenize the lyrics\n",
        "def tokenize_function(examples):\n",
        "    tokens = tokenizer(\n",
        "        examples[\"Lyric\"],\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "7EH3ehVNTQei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "K8DUTOfQU4-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Load GPT-2 medium model and resize embeddings\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "id": "JN3PKzHbTWYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-lyrics-finetuned\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    warmup_steps=500,\n",
        "    save_total_limit=2,\n",
        "    fp16=torch.cuda.is_available(),  # Use mixed precision if possible\n",
        ")"
      ],
      "metadata": {
        "id": "Rmr3NoKxTZ1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "o1VMXingTcNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "mhHwFgzBTd_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Save the fine-tuned model and tokenizer\n",
        "model.save_pretrained(\"./gpt2-lyrics-finetuned\")\n",
        "tokenizer.save_pretrained(\"./gpt2-lyrics-finetuned\")"
      ],
      "metadata": {
        "id": "8mk2WO11TgrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: using to(device())\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the saved model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained(\"./gpt2-lyrics-finetuned\").to(device)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"./gpt2-lyrics-finetuned\")\n",
        "tokenizer.pad_token = tokenizer.eos_token  # necessary fix\n"
      ],
      "metadata": {
        "id": "QZf9mHpAOX-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Generate lyrics with the fine-tuned model\n",
        "prompt = \"A romantic song about heartbreak:\\n\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(device)\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids=inputs[\"input_ids\"],\n",
        "    attention_mask=inputs[\"attention_mask\"],\n",
        "    max_length=200,            # allow longer output\n",
        "    min_length=100,            # enforce minimum length\n",
        "    do_sample=True,\n",
        "    temperature=0.9,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    no_repeat_ngram_size=3,\n",
        "    repetition_penalty=1.2,\n",
        "    pad_token_id=tokenizer.eos_token_id,    # pad token fix for GPT2\n",
        "    eos_token_id=tokenizer.eos_token_id,    # stop generation at EOS token\n",
        "    num_return_sequences=1,\n",
        ")\n",
        "\n",
        "print(\"Raw output token IDs:\\n\", output[0])\n",
        "\n",
        "lyrics = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "lyrics = lyrics[len(prompt):].strip()\n",
        "\n",
        "print(\"\\nðŸŽ¤ Generated Lyrics:\\n\")\n",
        "print(lyrics if lyrics else \"[No lyrics generated]\")\n"
      ],
      "metadata": {
        "id": "KMs9nPmkXZhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install TTS\n",
        "!pip install torchaudio"
      ],
      "metadata": {
        "id": "oQBcJDOQX_jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.api import TTS\n",
        "\n",
        "# Load Coqui TTS model (lightweight, CPU-friendly)\n",
        "tts = TTS(model_name=\"tts_models/en/ljspeech/tacotron2-DDC\", progress_bar=False, gpu=False)\n",
        "\n",
        "# Save spoken audio to file\n",
        "tts.tts_to_file(text=lyrics, file_path=\"lyrics.wav\")"
      ],
      "metadata": {
        "id": "mC9sQ7uKXaBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "file_path=\"lyrics.wav\" is just the filename (and optionally path) where your generated audio will be saved.\n",
        "\n"
      ],
      "metadata": {
        "id": "iZ33NyO9YUz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd\n",
        "\n",
        "# Play the audio file\n",
        "ipd.Audio(\"lyrics.wav\")"
      ],
      "metadata": {
        "id": "GDtVFJo7X7PM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n9yZ1FlOZFdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming logs are saved in './logs/events.out.tfevents...'\n",
        "# Or access trainer.state.log_history if available\n",
        "\n",
        "train_losses = []\n",
        "eval_losses = []\n",
        "\n",
        "for log in trainer.state.log_history:\n",
        "    if \"loss\" in log:\n",
        "        train_losses.append(log[\"loss\"])\n",
        "    if \"eval_loss\" in log:\n",
        "        eval_losses.append(log[\"eval_loss\"])\n",
        "\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(eval_losses, label=\"Eval Loss\")\n",
        "plt.xlabel(\"Logging Steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "onz_zAYSbmBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bertviz"
      ],
      "metadata": {
        "id": "TU9o639-ez1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "from bertviz import head_view\n",
        "\n",
        "# Load model with output_attentions=True\n",
        "model = GPT2Model.from_pretrained(\"gpt2\", output_attentions=True)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "text = \"Here is some sample text for attention visualization.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# Get attentions from outputs\n",
        "attentions = outputs.attentions  # tuple of tensors\n",
        "\n",
        "# Visualize attention heads with bertviz\n",
        "head_view(attentions, tokenizer.tokenize(text))\n",
        "\n"
      ],
      "metadata": {
        "id": "Nrg75-7mboi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text = lyrics  # your generated lyrics string\n",
        "\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FqI8Hyysb08_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Map sentiment to color codes (these are ANSI 256-color codes)\n",
        "color_map = {\n",
        "    'green': 82,   # bright green\n",
        "    'red': 196,    # bright red\n",
        "    'gray': 244    # gray\n",
        "}\n",
        "\n",
        "lines = lyrics.split('\\n')\n",
        "for line in lines:\n",
        "    polarity = TextBlob(line).sentiment.polarity\n",
        "    if polarity > 0.2:\n",
        "        color_code = color_map['blue']\n",
        "    elif polarity < -0.2:\n",
        "        color_code = color_map['gray']\n",
        "    else:\n",
        "        color_code = color_map['green']\n",
        "    print(f\"\\033[38;5;{color_code}m{line}\\033[0m\")\n"
      ],
      "metadata": {
        "id": "uJkLkJsjb3wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from textblob import TextBlob\n",
        "\n",
        "import re\n",
        "\n",
        "# Original single-line lyrics\n",
        "lyrics = \"'Cause it's cold in my chest, I'm feeling like an animal falling through the air when you call me back home again , don't worry babe we'll be right there waiting to tell ya what to do i know that if they're gonna hang us up then maybe let a rope run them down before hanging 'em all and burning their bodies off without ever saying goodbye oh yeah love is nothing but one more minute from this moment on so stay warm baby\"\n",
        "\n",
        "# Split on commas, conjunctions, or just every 10 words\n",
        "rough_lines = re.split(r',|\\band\\b|\\bso\\b', lyrics)\n",
        "\n",
        "# Optionally: Clean and strip each line\n",
        "lines = [line.strip().capitalize() for line in rough_lines if line.strip()]\n",
        "\n",
        "\n",
        "\n",
        "sentiments = [TextBlob(line).sentiment.polarity for line in lines]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(sentiments, marker='o', linestyle='-', color='teal')\n",
        "plt.title(\"Sentiment Progression Over Raw Generated Lyrics\")\n",
        "plt.xlabel(\"Line Number\")\n",
        "plt.ylabel(\"Sentiment Polarity\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Optional: print line with its polarity\n",
        "for i, (line, score) in enumerate(zip(lines, sentiments)):\n",
        "    print(f\"{i+1:02d}. ({score:.2f}) {line}\")\n"
      ],
      "metadata": {
        "id": "rBu5x0Y2b7BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "\n",
        "# Example lyrics (use your actual `lyrics` variable here)\n",
        "lines = lyrics.split('\\n')\n",
        "\n",
        "# Set figure size\n",
        "rcParams['figure.figsize'] = (8, len(lines) * 0.5)  # adjust height per number of lines\n",
        "\n",
        "# Create figure and axis\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Hide axes\n",
        "ax.axis('off')\n",
        "\n",
        "# Combine lines back into a single string for rendering\n",
        "text = \"\\n\".join(lines)\n",
        "\n",
        "# Add text to the figure\n",
        "ax.text(0.5, 0.5, text, ha='center', va='center', fontsize=14, wrap=True, family='monospace')\n",
        "\n",
        "# Show the plot\n",
        "plt.title(\"ðŸŽµ Generated Lyrics\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "E6hl9Sepgyp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import textwrap\n",
        "\n",
        "# Your generated lyrics\n",
        "text = lyrics.strip()\n",
        "\n",
        "# Settings\n",
        "width = 800\n",
        "padding = 50\n",
        "background_color = \"black\"\n",
        "text_color = \"white\"\n",
        "font_size = 28\n",
        "line_spacing = 10\n",
        "\n",
        "# Load a font (fallback to default if font not found)\n",
        "try:\n",
        "    font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
        "except:\n",
        "    font = ImageFont.load_default()\n",
        "\n",
        "# Wrap text\n",
        "wrapper = textwrap.TextWrapper(width=40)\n",
        "lines = wrapper.wrap(text=text)\n",
        "\n",
        "# Estimate height\n",
        "height = padding * 2 + (font_size + line_spacing) * len(lines)\n",
        "\n",
        "# Create image\n",
        "img = Image.new(\"RGB\", (width, height), color=background_color)\n",
        "draw = ImageDraw.Draw(img)\n",
        "\n",
        "# Draw each line\n",
        "y_text = padding\n",
        "for line in lines:\n",
        "    draw.text((padding, y_text), line, font=font, fill=text_color)\n",
        "    y_text += font_size + line_spacing\n",
        "\n",
        "# Save and display\n",
        "img_path = \"lyrics_poster.png\"\n",
        "img.save(img_path)\n",
        "\n",
        "# Display in Colab\n",
        "import IPython.display as display\n",
        "display.display(img)\n"
      ],
      "metadata": {
        "id": "1ElPNYxGhCvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Settings\n",
        "width = 600\n",
        "padding = 10\n",
        "background_color = \"pink\"\n",
        "text_color = \"black\"\n",
        "font_size = 16\n",
        "line_spacing = 8\n",
        "\n",
        "try:\n",
        "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSans-Italic.ttf\", font_size)\n",
        "\n",
        "except:\n",
        "    font = ImageFont.load_default()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "wrapper = textwrap.TextWrapper(width=40)\n",
        "lines = wrapper.wrap(text=text)\n",
        "\n",
        "\n",
        "height = padding * 2 + (font_size + line_spacing) * len(lines)\n",
        "\n",
        "img = Image.new(\"RGB\", (width, height), color=background_color)\n",
        "draw = ImageDraw.Draw(img)\n",
        "\n",
        "\n",
        "y_text = padding\n",
        "for line in lines:\n",
        "    draw.text((padding, y_text), line, font=font, fill=text_color)\n",
        "    y_text += font_size + line_spacing\n",
        "\n",
        "img_path = \"lyrics_poster.png\"\n",
        "img.save(img_path)\n",
        "\n",
        "import IPython.display as display\n",
        "display.display(img)\n"
      ],
      "metadata": {
        "id": "55A7Th0AhcUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "possible_folders = [\n",
        "    \"/usr/share/fonts\",\n",
        "    \"/usr/local/share/fonts\",\n",
        "    os.path.expanduser(\"~/.fonts\"),\n",
        "]\n",
        "\n",
        "found = False\n",
        "for folder in possible_folders:\n",
        "    if os.path.exists(folder):\n",
        "        print(f\"Fonts qovluÄŸu tapÄ±ldÄ±: {folder}\")\n",
        "        print(\"Ä°Ã§indÉ™kilÉ™r:\")\n",
        "        for root, dirs, files in os.walk(folder):\n",
        "            for file in files:\n",
        "                if file.lower().endswith(\".ttf\"):\n",
        "                    print(os.path.join(root, file))\n",
        "        found = True\n",
        "        break\n",
        "\n",
        "if not found:\n",
        "    print(\"HeÃ§ bir fonts qovluÄŸu tapÄ±lmadÄ±.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WhVoaghqhcRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HD6-vb5Mkf5L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}