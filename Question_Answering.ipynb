{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOg4y7v6SPihrY4mA3ii43m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leman-cap13/NLP_projects/blob/main/Question_Answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znoj5zz5a3Sl"
      },
      "outputs": [],
      "source": [
        "from datasets import get_dataset_config_names\n",
        "\n",
        "domains=get_dataset_config_names(\"subjqa\")\n",
        "domains"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets --upgrade"
      ],
      "metadata": {
        "id": "aKI1Uw66a7zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "subjqa=load_dataset(\"subjqa\", name='electronics')\n",
        "subjqa"
      ],
      "metadata": {
        "id": "ApZVgLJra7wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#open domain and close-domain(spesific)"
      ],
      "metadata": {
        "id": "-LOr1-5gedUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(subjqa['train']['answers'][1])"
      ],
      "metadata": {
        "id": "HAR5LhYvedQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(subjqa['train'][1])"
      ],
      "metadata": {
        "id": "auFgODQ_edLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "dfs={split : dset.to_pandas() for split, dset in subjqa.flatten().items()}\n",
        "\n",
        "for split, df in dfs.items():\n",
        "  print(f\"Numner of questions in { split}: { df['id'].nunique()}\")"
      ],
      "metadata": {
        "id": "nqzjrBcvgM_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_cols=['title','question', 'answers.text', 'answers.answer_start', 'context']\n",
        "sample_df=dfs['train'][qa_cols].sample(2, random_state=7)\n",
        "sample_df"
      ],
      "metadata": {
        "id": "6eQ91W-UgM8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_idx=sample_df['answers.answer_start'].iloc[0][0]\n",
        "end_idx=start_idx+len(sample_df['answers.text'].iloc[0][0])\n",
        "sample_df['context'].iloc[0][start_idx:end_idx]"
      ],
      "metadata": {
        "id": "R7tfpWfmijTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "IF5gPfSIme-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts={}\n",
        "question_types=['What','How','Is','Does','Do','Was','Where','Why']\n",
        "\n",
        "for q in question_types:\n",
        "    counts[q]=dfs['train']['question'].str.startswith(q).value_counts()[True]\n",
        "\n",
        "pd.Series(counts).sort_values().plot.barh()\n",
        "plt.title('Frequency of Question Types')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "3Tl_wmNtiqgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for question_type in ['How','What','Is']:\n",
        "  for question in (\n",
        "      dfs['train'][dfs['train'].question.str.startswith(question_type)]\n",
        "      .sample(n=3, random_state=42)['question']):\n",
        "      print(question)\n"
      ],
      "metadata": {
        "id": "8upeOC9Viqci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenizing text for QA"
      ],
      "metadata": {
        "id": "HSDYLaKEiqaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_ckpt='deepset/minilm-uncased-squad2'\n",
        "tokenizer=AutoTokenizer.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "LWK6jWsBmjuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#minilm"
      ],
      "metadata": {
        "id": "Nqk_e3tomjrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question='How much music can this hold?'\n",
        "context='An MP3 is about 1 MB/minute, so about 6000 hours depending on file size'\n",
        "inputs=tokenizer(question, context, return_tensors='pt')"
      ],
      "metadata": {
        "id": "IdhMH4msoOfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_df=pd.DataFrame.from_dict(tokenizer(question, context), orient='index')\n",
        "input_df"
      ],
      "metadata": {
        "id": "K_eeYUmGoOcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(inputs['input_ids'][0]))"
      ],
      "metadata": {
        "id": "WZWeiGSHqeUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "\n",
        "model=AutoModelForQuestionAnswering.from_pretrained(model_ckpt)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  outputs=model(**inputs)\n",
        "\n",
        "print(outputs)"
      ],
      "metadata": {
        "id": "ZqqmZNTxqeQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "IQMVN9r-u210"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_scores=outputs.start_logits.detach().numpy().flatten()\n",
        "e_scores=outputs.end_logits.detach().numpy().flatten()\n",
        "tokens=tokenizer.convert_ids_to_tokens(inputs['input_ids'].numpy()[0])\n",
        "\n",
        "fig, (ax1,ax2)=plt.subplots(nrows=2,sharex=True, figsize=(10,4))\n",
        "colors=['C0' if s!=np.max(s_scores) else 'C1' for s in s_scores]\n",
        "ax1.bar(x=tokens, height=s_scores, color=colors)\n",
        "ax1.set_ylabel('Start Scores')\n",
        "colors=['C0' if e!=np.max(e_scores) else 'C1' for e in e_scores]\n",
        "ax2.bar(x=tokens, height=e_scores, color=colors)\n",
        "ax2.set_ylabel('End Scores')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jrX0SxOcrm3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "start_logits=outputs.start_logits\n",
        "end_logits=outputs.end_logits\n",
        "\n",
        "start_idx=torch.argmax(start_logits)\n",
        "end_idx=torch.argmax(end_logits)\n",
        "answer_span=inputs['input_ids'][0][start_idx: end_idx]\n",
        "answer=tokenizer.decode(answer_span)\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "id": "byRgVZj9rm0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extractive only encoder, anstractive encoder- decoder modellerden istifade edir"
      ],
      "metadata": {
        "id": "U9gI0aFQrmx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe=pipeline('question-answering', model=model, tokenizer=tokenizer)\n",
        "pipe(question=question, context=context, topk=3)"
      ],
      "metadata": {
        "id": "udpgxxZXtOSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#what if we dont have an answer?\n",
        "\n",
        "pipe(question='Why is there no data?', context=context, handle_impossible_answer=True)"
      ],
      "metadata": {
        "id": "f2F_gXqvtOPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if answer pass context size(512 tokens)\n",
        "#sliding window ve ya logformer bigbird kimi modeller"
      ],
      "metadata": {
        "id": "mDzMJb1kwipq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dealing with long passages"
      ],
      "metadata": {
        "id": "uzTAv9fQwiY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_input_length(row):\n",
        "  inputs=tokenizer(row['question'], row['context'])\n",
        "  return len(inputs['input_ids'])\n",
        "dfs['train']['n_tokens']=dfs['train'].apply(compute_input_length, axis=1)\n",
        "\n",
        "fig, ax=plt.subplots()\n",
        "dfs['train']['n_tokens'].hist(bins=100, grid=False, ax=ax)\n",
        "plt.xlabel('Number of tokens in question-context pair')\n",
        "ax.axvline(x=512, ymin=0, ymax=1, linestyle='--',\n",
        "           color='C1', label='Maximum sequence length')\n",
        "\n",
        "plt.legend()\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-LjhJrd2xaqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example=dfs['train'].iloc[0][['question','context']]\n",
        "tokenized_example=tokenizer(example['question'],example['context'],\n",
        "                            return_overflowing_tokens=True,max_length=100,\n",
        "                            stride=25,truncation=True)\n"
      ],
      "metadata": {
        "id": "AmEgEushzVbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, window in enumerate(tokenized_example['input_ids']):\n",
        "  print(f\"window #{idx} has {len(window)} tokens\")"
      ],
      "metadata": {
        "id": "Nuak6VwRzVX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for window in tokenized_example['input_ids']:\n",
        "  print(f'{tokenizer.decode(window)}\\n')"
      ],
      "metadata": {
        "id": "w35p66jOw1G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using Haystack to build a QA Pipeline"
      ],
      "metadata": {
        "id": "JQ74scTaw1Dg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"\"\"https://artifacts.elastic.co/downloads/elasticsearch/\\\n",
        "elasticsearch-7.9.2-linux-x86_64.tar.gz\"\"\"\n",
        "!wget -nc -q {url}\n",
        "!tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz"
      ],
      "metadata": {
        "id": "YMovk_70xFvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "\n",
        "# Run Elasticsearch as a background process\n",
        "!chown -R daemon:daemon elasticsearch-7.9.2\n",
        "es_server = Popen(args=['elasticsearch-7.9.2/bin/elasticsearch'],\n",
        "                  stdout=PIPE, stderr=STDOUT, preexec_fn=lambda: os.setuid(1))\n",
        "# Wait until Elasticsearch has started\n",
        "!sleep 30"
      ],
      "metadata": {
        "id": "UJ2rIgG6xFrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Popen ? arxa planda run etmek"
      ],
      "metadata": {
        "id": "3PvgYUda29Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X GET 'localhost:9200/?pretty'"
      ],
      "metadata": {
        "id": "6JulDFmG29E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  datasets --upgrade"
      ],
      "metadata": {
        "id": "lFkR-g3u4wS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install farm-haystack[elasticsearch]"
      ],
      "metadata": {
        "id": "pq_nr6VY4oUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.document_stores import ElasticsearchDocumentStore\n",
        "\n"
      ],
      "metadata": {
        "id": "MkP4iuo029Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_store=ElasticsearchDocumentStore(\n",
        "    host='localhost',\n",
        "    port=9200,\n",
        "    username='',\n",
        "    password='',\n",
        "    index='document',\n",
        "    return_embedding=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "_sIX7kxR3vmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for split , df in dfs.items():\n",
        "  docs=[{'content':row['context'],\n",
        "         'meta':{'item_id':row['title'], 'question_id': row['id'],\n",
        "                 'split': split}}\n",
        "        for _,row in df.drop_duplicates(subset='context').iterrows()]\n",
        "  document_store.write_documents(docs,index='document')\n",
        "print(f\"Loaded { document_store.get_document_count()} documents\")\n"
      ],
      "metadata": {
        "id": "LqMI8_4Y5pgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cunki retrievel xussui format gozleyir content meta"
      ],
      "metadata": {
        "id": "hzKzJvtc5pcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initializing a retriever"
      ],
      "metadata": {
        "id": "OTHySodg7PV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import BM25Retriever\n",
        "\n",
        "retriever=BM25Retriever(document_store=document_store)"
      ],
      "metadata": {
        "id": "uF0PX4SW7PNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_id='B0074BW614'\n",
        "querry='Is it good for reading?'\n",
        "retriever_docs=retriever.retrieve(query=querry, top_k=3,\n",
        "                                  filters={'item_id':[item_id],\n",
        "                                           'split':['train']})"
      ],
      "metadata": {
        "id": "rEYhDE3z7PJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_docs[0].content"
      ],
      "metadata": {
        "id": "v9AaFBvw8oRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_docs[1].content"
      ],
      "metadata": {
        "id": "iq8hlN6M8oOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initializing a reader"
      ],
      "metadata": {
        "id": "b1KwWRMZ945p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import TransformersReader\n",
        "\n",
        "model_ckpt='deepset/minilm-uncased-squad2'\n",
        "reader=TransformersReader(\n",
        "    model_name_or_path=model_ckpt,\n",
        "    max_seq_len=384,\n",
        "    doc_stride=128\n",
        ")"
      ],
      "metadata": {
        "id": "Qn4SY44D942Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Putting it all together"
      ],
      "metadata": {
        "id": "9uqVshak94z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.pipelines import ExtractiveQAPipeline\n",
        "\n",
        "pipe=ExtractiveQAPipeline(reader=reader, retriever=retriever)"
      ],
      "metadata": {
        "id": "SOcD6KqW-wxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_answers=3\n",
        "preds=pipe.run(\n",
        "    query=querry,\n",
        "    params={\n",
        "        'Retriever':{'top_k':3,\n",
        "                     'filters':{'item_id':[item_id],\n",
        "                                'split': ['train']}},\n",
        "        'Reader' : { 'top_k': n_answers}\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "KYDg-y52-wuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Qustion: { preds['query']}\\n\")\n",
        "answers=preds.get('answers',[])\n",
        "\n",
        "if not answers:\n",
        "  print('No answers found')\n",
        "else:\n",
        "  for idx,ans in enumerate(answers):\n",
        "    print(f\"Answer {idx+1}: {ans.answer}\")\n",
        "    print(f\"Review snippet:...{ans.context}...\\n\")\n"
      ],
      "metadata": {
        "id": "AYwoUkslBO0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MgRpO6NZBOw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mIKG3A1uCAkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wTct-K0yCAhB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}