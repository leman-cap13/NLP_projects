{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leman-cap13/my_projects/blob/main/Multi_Task_NER_POS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model"
      ],
      "metadata": {
        "id": "DkHyZbVCmbEf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "_aqdi-WDx1jW",
        "outputId": "0bc345c2-1203-451f-c6f3-fbadc84b5c01"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a8038e61-5262-47c5-9e1b-514ee2c17caa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a8038e61-5262-47c5-9e1b-514ee2c17caa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (3).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle (3).json': b'{\"username\":\"lmanqasml\",\"key\":\"2d851a4eb9cae06770577185722326e0\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "7x7l0GdpyKbv"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y63PIUi_yYOu",
        "outputId": "3171102b-761b-4ac1-b4c7-c97f8c948cbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/rohitr4307/ner-dataset\n",
            "License(s): unknown\n",
            "ner-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download rohitr4307/ner-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "J2NK45lEygxf"
      },
      "outputs": [],
      "source": [
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "NtnNOe0CywKf"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile('/content/ner-dataset.zip','r') as zip_ref:\n",
        "  zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "kpaowh0sy9dX",
        "outputId": "cf2141eb-abfe-4cc6-931e-de4d31403ee5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Sentence_ID                                               Word  \\\n",
              "0          Sentence: 1  ['Thousands', 'of', 'demonstrators', 'have', '...   \n",
              "1         Sentence: 10  ['Iranian', 'officials', 'say', 'they', 'expec...   \n",
              "2        Sentence: 100  ['Helicopter', 'gunships', 'Saturday', 'pounde...   \n",
              "3       Sentence: 1000  ['They', 'left', 'after', 'a', 'tense', 'hour-...   \n",
              "4      Sentence: 10000  ['U.N.', 'relief', 'coordinator', 'Jan', 'Egel...   \n",
              "...                ...                                                ...   \n",
              "47954   Sentence: 9995  ['Opposition', 'leader', 'Mir', 'Hossein', 'Mo...   \n",
              "47955   Sentence: 9996  ['On', 'Thursday', ',', 'Iranian', 'state', 'm...   \n",
              "47956   Sentence: 9997  ['Following', 'Iran', \"'s\", 'disputed', 'June'...   \n",
              "47957   Sentence: 9998  ['Since', 'then', ',', 'authorities', 'have', ...   \n",
              "47958   Sentence: 9999  ['The', 'United', 'Nations', 'is', 'praising',...   \n",
              "\n",
              "                                                     POS  \\\n",
              "0      ['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...   \n",
              "1      ['JJ', 'NNS', 'VBP', 'PRP', 'VBP', 'TO', 'VB',...   \n",
              "2      ['NN', 'NNS', 'NNP', 'VBD', 'JJ', 'NNS', 'IN',...   \n",
              "3      ['PRP', 'VBD', 'IN', 'DT', 'NN', 'JJ', 'NN', '...   \n",
              "4      ['NNP', 'NN', 'NN', 'NNP', 'NNP', 'VBD', 'NNP'...   \n",
              "...                                                  ...   \n",
              "47954  ['NNP', 'NN', 'NNP', 'NNP', 'NNP', 'VBZ', 'VBN...   \n",
              "47955  ['IN', 'NNP', ',', 'JJ', 'NN', 'NNS', 'VBN', '...   \n",
              "47956  ['VBG', 'NNP', 'POS', 'JJ', 'NNP', 'CD', 'NNS'...   \n",
              "47957  ['IN', 'RB', ',', 'NNS', 'VBP', 'VBN', 'JJ', '...   \n",
              "47958  ['DT', 'NNP', 'NNP', 'VBZ', 'VBG', 'DT', 'NN',...   \n",
              "\n",
              "                                                     Tag  \n",
              "0      ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...  \n",
              "1      ['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '...  \n",
              "2      ['O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', '...  \n",
              "3      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
              "4      ['B-geo', 'O', 'O', 'B-per', 'I-per', 'O', 'B-...  \n",
              "...                                                  ...  \n",
              "47954  ['O', 'O', 'O', 'B-per', 'I-per', 'O', 'O', 'O...  \n",
              "47955  ['O', 'B-tim', 'O', 'B-gpe', 'O', 'O', 'O', 'O...  \n",
              "47956  ['O', 'B-geo', 'O', 'O', 'B-tim', 'I-tim', 'O'...  \n",
              "47957  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
              "47958  ['O', 'B-org', 'I-org', 'O', 'O', 'O', 'O', 'O...  \n",
              "\n",
              "[47959 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63fc2605-5de8-4c58-91e1-0a48fae437a9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence_ID</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>['Thousands', 'of', 'demonstrators', 'have', '...</td>\n",
              "      <td>['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...</td>\n",
              "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 10</td>\n",
              "      <td>['Iranian', 'officials', 'say', 'they', 'expec...</td>\n",
              "      <td>['JJ', 'NNS', 'VBP', 'PRP', 'VBP', 'TO', 'VB',...</td>\n",
              "      <td>['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 100</td>\n",
              "      <td>['Helicopter', 'gunships', 'Saturday', 'pounde...</td>\n",
              "      <td>['NN', 'NNS', 'NNP', 'VBD', 'JJ', 'NNS', 'IN',...</td>\n",
              "      <td>['O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1000</td>\n",
              "      <td>['They', 'left', 'after', 'a', 'tense', 'hour-...</td>\n",
              "      <td>['PRP', 'VBD', 'IN', 'DT', 'NN', 'JJ', 'NN', '...</td>\n",
              "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 10000</td>\n",
              "      <td>['U.N.', 'relief', 'coordinator', 'Jan', 'Egel...</td>\n",
              "      <td>['NNP', 'NN', 'NN', 'NNP', 'NNP', 'VBD', 'NNP'...</td>\n",
              "      <td>['B-geo', 'O', 'O', 'B-per', 'I-per', 'O', 'B-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47954</th>\n",
              "      <td>Sentence: 9995</td>\n",
              "      <td>['Opposition', 'leader', 'Mir', 'Hossein', 'Mo...</td>\n",
              "      <td>['NNP', 'NN', 'NNP', 'NNP', 'NNP', 'VBZ', 'VBN...</td>\n",
              "      <td>['O', 'O', 'O', 'B-per', 'I-per', 'O', 'O', 'O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47955</th>\n",
              "      <td>Sentence: 9996</td>\n",
              "      <td>['On', 'Thursday', ',', 'Iranian', 'state', 'm...</td>\n",
              "      <td>['IN', 'NNP', ',', 'JJ', 'NN', 'NNS', 'VBN', '...</td>\n",
              "      <td>['O', 'B-tim', 'O', 'B-gpe', 'O', 'O', 'O', 'O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47956</th>\n",
              "      <td>Sentence: 9997</td>\n",
              "      <td>['Following', 'Iran', \"'s\", 'disputed', 'June'...</td>\n",
              "      <td>['VBG', 'NNP', 'POS', 'JJ', 'NNP', 'CD', 'NNS'...</td>\n",
              "      <td>['O', 'B-geo', 'O', 'O', 'B-tim', 'I-tim', 'O'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47957</th>\n",
              "      <td>Sentence: 9998</td>\n",
              "      <td>['Since', 'then', ',', 'authorities', 'have', ...</td>\n",
              "      <td>['IN', 'RB', ',', 'NNS', 'VBP', 'VBN', 'JJ', '...</td>\n",
              "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47958</th>\n",
              "      <td>Sentence: 9999</td>\n",
              "      <td>['The', 'United', 'Nations', 'is', 'praising',...</td>\n",
              "      <td>['DT', 'NNP', 'NNP', 'VBZ', 'VBG', 'DT', 'NN',...</td>\n",
              "      <td>['O', 'B-org', 'I-org', 'O', 'O', 'O', 'O', 'O...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47959 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63fc2605-5de8-4c58-91e1-0a48fae437a9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-63fc2605-5de8-4c58-91e1-0a48fae437a9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-63fc2605-5de8-4c58-91e1-0a48fae437a9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8865adfd-18c3-4103-ac14-c14206b738b8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8865adfd-18c3-4103-ac14-c14206b738b8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8865adfd-18c3-4103-ac14-c14206b738b8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_adb2c16f-024a-424e-a5e6-78a59b92298a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_adb2c16f-024a-424e-a5e6-78a59b92298a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 47959,\n  \"fields\": [\n    {\n      \"column\": \"Sentence_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47959,\n        \"samples\": [\n          \"Sentence: 22048\",\n          \"Sentence: 1273\",\n          \"Sentence: 1541\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47575,\n        \"samples\": [\n          \"['The', 'Afghan', 'civilians', 'were', 'killed', 'during', 'a', 'firefight', 'between', 'the', 'Polish', 'troops', 'and', 'militants', 'on', 'August', '16', '.']\",\n          \"['President', 'Bush', 'is', 'to', 'travel', 'to', 'Europe', 'in', 'June', 'to', 'attend', 'a', 'summit', 'of', 'the', 'Group', 'of', 'Eight', 'industrialized', 'nations', 'in', 'Germany', '.']\",\n          \"['Russian', 'news', 'reports', 'say', 'a', 'court', 'ruled', 'Monday', 'that', 'Mikhail', 'Khodorkovsky', 'and', 'his', 'business', 'partner', 'are', 'guilty', 'of', 'embezzling', 'property', '.']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POS\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47214,\n        \"samples\": [\n          \"['PRP', 'VBD', 'DT', 'JJ', 'NN', 'IN', 'NNP', 'NNP', 'VBD', 'NN', 'IN', 'CD', 'IN', 'PRP', 'VBD', 'RB', 'VB', 'DT', 'JJ', 'NN', '.']\",\n          \"['NNS', 'VBP', 'DT', 'NN', 'VBD', 'NN', 'IN', 'DT', 'CD', 'NNS', 'VBD', 'VBG', 'DT', 'JJ', 'JJ', 'NN', 'IN', 'NNP', 'NN', '.']\",\n          \"['DT', 'NN', 'RB', 'VBD', 'DT', 'NN', 'IN', 'NNP', 'IN', 'VBG', 'IN', 'CD', 'CC', 'CD', 'NNS', 'IN', 'DT', 'JJ', 'NN', 'NN', 'TO', 'VB', 'DT', 'NN', ',', 'CD', ',', 'CD', ',', 'CD', '.']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tag\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33318,\n        \"samples\": [\n          \"['O', 'O', 'O', 'O', 'O', 'B-per', 'B-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O']\",\n          \"['O', 'B-tim', 'O', 'B-gpe', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'B-gpe', 'O', 'O']\",\n          \"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 180
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/NER_Dataset.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzK1tJ0X0tue",
        "outputId": "ac579fd1-17ef-487f-fb03-e485415f3ede"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Sentence_ID', 'Word', 'POS', 'Tag'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "RjsRm7sU2WX7",
        "outputId": "604f88f5-ed6e-4fbd-b1cf-55b03264fd4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"['U.N.', 'relief', 'coordinator', 'Jan', 'Egeland', 'said', 'Sunday', ',', 'U.S.', ',', 'Indonesian', 'and', 'Australian', 'military', 'helicopters', 'are', 'ferrying', 'out', 'food', 'and', 'supplies', 'to', 'remote', 'areas', 'of', 'western', 'Aceh', 'province', 'that', 'ground', 'crews', 'can', 'not', 'reach', '.']\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 182
        }
      ],
      "source": [
        "df['Word'].iloc[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfZptOSp2eEO",
        "outputId": "60a2a167-1408-4520-c668-9a83e130a58e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\",\n",
              "       \"['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'B-org', 'O', 'O', 'O', 'O', 'O']\",\n",
              "       \"['O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'I-geo', 'O']\",\n",
              "       ...,\n",
              "       \"['O', 'B-tim', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-org', 'I-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\",\n",
              "       \"['O', 'B-geo', 'O', 'O', 'B-tim', 'I-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\",\n",
              "       \"['O', 'B-org', 'I-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'I-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ],
      "source": [
        "df['Tag'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "ac8XNFXo2eAu"
      },
      "outputs": [],
      "source": [
        "#B-gpe, B-tim, B-geo, B-org,I-geo, I-org, I-tim ---BIO Formats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "VOK_-H3p3b5I"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "9qHam1sO3xxW"
      },
      "outputs": [],
      "source": [
        "# First Step Tokenization\n",
        "# our input is already token"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Token to token id"
      ],
      "metadata": {
        "id": "PulmMK7I3f0L"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "x6VkqnDKGqwg"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "df['Word'] = df['Word'].apply(ast.literal_eval)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pos ucun Eval appyle et\n",
        "df['POS']=df['POS'].apply(ast.literal_eval)"
      ],
      "metadata": {
        "id": "LCFGgnFqp2JA"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GW4rsy__p54J"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FLFW8tKYp55A"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "KXgYs3e4Gvhd",
        "outputId": "da6a8d62-5a61-48b9-f993-0346c86d6e32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [Thousands, of, demonstrators, have, marched, ...\n",
              "1    [Iranian, officials, say, they, expect, to, ge...\n",
              "2    [Helicopter, gunships, Saturday, pounded, mili...\n",
              "3    [They, left, after, a, tense, hour-long, stand...\n",
              "4    [U.N., relief, coordinator, Jan, Egeland, said...\n",
              "Name: Word, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[They, left, after, a, tense, hour-long, stand...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[U.N., relief, coordinator, Jan, Egeland, said...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ],
      "source": [
        "df['Word'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk90uLJ-HN8X",
        "outputId": "374ba859-da22-484d-bdcd-d6f6424459ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Thousands',\n",
              " 'of',\n",
              " 'demonstrators',\n",
              " 'have',\n",
              " 'marched',\n",
              " 'through',\n",
              " 'London',\n",
              " 'to',\n",
              " 'protest',\n",
              " 'the',\n",
              " 'war',\n",
              " 'in',\n",
              " 'Iraq',\n",
              " 'and',\n",
              " 'demand',\n",
              " 'the',\n",
              " 'withdrawal',\n",
              " 'of',\n",
              " 'British',\n",
              " 'troops',\n",
              " 'from',\n",
              " 'that',\n",
              " 'country',\n",
              " '.',\n",
              " 'Iranian',\n",
              " 'officials',\n",
              " 'say',\n",
              " 'they',\n",
              " 'expect',\n",
              " 'to',\n",
              " 'get',\n",
              " 'access',\n",
              " 'to',\n",
              " 'sealed',\n",
              " 'sensitive',\n",
              " 'parts',\n",
              " 'of',\n",
              " 'the',\n",
              " 'plant',\n",
              " 'Wednesday',\n",
              " ',',\n",
              " 'after',\n",
              " 'an',\n",
              " 'IAEA',\n",
              " 'surveillance',\n",
              " 'system',\n",
              " 'begins',\n",
              " 'functioning',\n",
              " '.',\n",
              " 'Helicopter',\n",
              " 'gunships',\n",
              " 'Saturday',\n",
              " 'pounded',\n",
              " 'militant',\n",
              " 'hideouts',\n",
              " 'in',\n",
              " 'the',\n",
              " 'Orakzai',\n",
              " 'tribal',\n",
              " 'region',\n",
              " ',',\n",
              " 'where',\n",
              " 'many',\n",
              " 'Taliban',\n",
              " 'militants',\n",
              " 'are',\n",
              " 'believed',\n",
              " 'to',\n",
              " 'have',\n",
              " 'fled',\n",
              " 'to',\n",
              " 'avoid',\n",
              " 'an',\n",
              " 'earlier',\n",
              " 'military',\n",
              " 'offensive',\n",
              " 'in',\n",
              " 'nearby',\n",
              " 'South',\n",
              " 'Waziristan',\n",
              " '.',\n",
              " 'They',\n",
              " 'left',\n",
              " 'after',\n",
              " 'a',\n",
              " 'tense',\n",
              " 'hour-long',\n",
              " 'standoff',\n",
              " 'with',\n",
              " 'riot',\n",
              " 'police',\n",
              " '.',\n",
              " 'U.N.',\n",
              " 'relief',\n",
              " 'coordinator',\n",
              " 'Jan',\n",
              " 'Egeland',\n",
              " 'said',\n",
              " 'Sunday',\n",
              " ',',\n",
              " 'U.S.',\n",
              " ',',\n",
              " 'Indonesian',\n",
              " 'and',\n",
              " 'Australian',\n",
              " 'military',\n",
              " 'helicopters',\n",
              " 'are',\n",
              " 'ferrying',\n",
              " 'out',\n",
              " 'food',\n",
              " 'and',\n",
              " 'supplies',\n",
              " 'to',\n",
              " 'remote',\n",
              " 'areas',\n",
              " 'of',\n",
              " 'western',\n",
              " 'Aceh',\n",
              " 'province',\n",
              " 'that',\n",
              " 'ground',\n",
              " 'crews',\n",
              " 'can',\n",
              " 'not',\n",
              " 'reach',\n",
              " '.',\n",
              " 'Mr.',\n",
              " 'Egeland',\n",
              " 'said',\n",
              " 'the',\n",
              " 'latest',\n",
              " 'figures',\n",
              " 'show',\n",
              " '1.8',\n",
              " 'million',\n",
              " 'people',\n",
              " 'are',\n",
              " 'in',\n",
              " 'need',\n",
              " 'of',\n",
              " 'food',\n",
              " 'assistance',\n",
              " '-',\n",
              " 'with',\n",
              " 'the',\n",
              " 'need',\n",
              " 'greatest',\n",
              " 'in',\n",
              " 'Indonesia',\n",
              " ',',\n",
              " 'Sri',\n",
              " 'Lanka',\n",
              " ',',\n",
              " 'the',\n",
              " 'Maldives',\n",
              " 'and',\n",
              " 'India',\n",
              " '.',\n",
              " 'He',\n",
              " 'said',\n",
              " 'last',\n",
              " 'week',\n",
              " \"'s\",\n",
              " 'tsunami',\n",
              " 'and',\n",
              " 'the',\n",
              " 'massive',\n",
              " 'underwater',\n",
              " 'earthquake',\n",
              " 'that',\n",
              " 'triggered',\n",
              " 'it',\n",
              " 'has',\n",
              " 'affected',\n",
              " 'millions',\n",
              " 'in',\n",
              " 'Asia',\n",
              " 'and',\n",
              " 'Africa',\n",
              " '.',\n",
              " 'Some',\n",
              " '1,27,000',\n",
              " 'people',\n",
              " 'are',\n",
              " 'known',\n",
              " 'dead',\n",
              " '.',\n",
              " 'Aid',\n",
              " 'is',\n",
              " 'being',\n",
              " 'rushed',\n",
              " 'to',\n",
              " 'the',\n",
              " 'region',\n",
              " ',',\n",
              " 'but',\n",
              " 'the',\n",
              " 'U.N.',\n",
              " 'official',\n",
              " 'stressed',\n",
              " 'that',\n",
              " 'bottlenecks',\n",
              " 'and',\n",
              " 'a',\n",
              " 'lack',\n",
              " 'of',\n",
              " 'infrastructure',\n",
              " 'remain',\n",
              " 'a',\n",
              " 'challenge',\n",
              " '.',\n",
              " 'Lebanese',\n",
              " 'politicians',\n",
              " 'are',\n",
              " 'condemning',\n",
              " 'Friday',\n",
              " \"'s\",\n",
              " 'bomb',\n",
              " 'blast',\n",
              " 'in',\n",
              " 'a',\n",
              " 'Christian',\n",
              " 'neighborhood',\n",
              " 'of',\n",
              " 'Beirut',\n",
              " 'as',\n",
              " 'an',\n",
              " 'attempt',\n",
              " 'to',\n",
              " 'sow',\n",
              " 'sectarian',\n",
              " 'strife',\n",
              " 'in',\n",
              " 'the',\n",
              " 'formerly',\n",
              " 'war-torn',\n",
              " 'country',\n",
              " '.',\n",
              " 'In',\n",
              " 'Beirut',\n",
              " ',',\n",
              " 'a',\n",
              " 'string',\n",
              " 'of',\n",
              " 'officials',\n",
              " 'voiced',\n",
              " 'their',\n",
              " 'anger',\n",
              " ',',\n",
              " 'while',\n",
              " 'at',\n",
              " 'the',\n",
              " 'United',\n",
              " 'Nations',\n",
              " 'summit',\n",
              " 'in',\n",
              " 'New',\n",
              " 'York',\n",
              " ',',\n",
              " 'Prime',\n",
              " 'Minister',\n",
              " 'Fouad',\n",
              " 'Siniora',\n",
              " 'said',\n",
              " 'the',\n",
              " 'Lebanese',\n",
              " 'people',\n",
              " 'are',\n",
              " 'resolute',\n",
              " 'in',\n",
              " 'preventing',\n",
              " 'such',\n",
              " 'attempts',\n",
              " 'from',\n",
              " 'destroying',\n",
              " 'their',\n",
              " 'spirit',\n",
              " '.',\n",
              " 'One',\n",
              " 'person',\n",
              " 'was',\n",
              " 'killed',\n",
              " 'and',\n",
              " 'more',\n",
              " 'than',\n",
              " '20',\n",
              " 'others',\n",
              " 'injured',\n",
              " 'in',\n",
              " 'the',\n",
              " 'bomb',\n",
              " 'blast',\n",
              " 'late',\n",
              " 'Friday',\n",
              " ',',\n",
              " 'which',\n",
              " 'took',\n",
              " 'place',\n",
              " 'on',\n",
              " 'a',\n",
              " 'residential',\n",
              " 'street',\n",
              " '.',\n",
              " 'Lebanon',\n",
              " 'has',\n",
              " 'suffered',\n",
              " 'a',\n",
              " 'series',\n",
              " 'of',\n",
              " 'bombings',\n",
              " 'since',\n",
              " 'the',\n",
              " 'massive',\n",
              " 'explosion',\n",
              " 'in',\n",
              " 'February',\n",
              " 'that',\n",
              " 'killed',\n",
              " 'former',\n",
              " 'Prime',\n",
              " 'Minister',\n",
              " 'Rafik',\n",
              " 'Hariri',\n",
              " 'and',\n",
              " '20',\n",
              " 'other',\n",
              " 'people',\n",
              " '.',\n",
              " 'Syria',\n",
              " 'is',\n",
              " 'widely',\n",
              " 'accused',\n",
              " 'of',\n",
              " 'involvement',\n",
              " 'in',\n",
              " 'his',\n",
              " 'killing',\n",
              " ',',\n",
              " 'and',\n",
              " 'Friday',\n",
              " \"'s\",\n",
              " 'explosion',\n",
              " 'comes',\n",
              " 'days',\n",
              " 'before',\n",
              " 'U.N.',\n",
              " 'investigator',\n",
              " 'Detlev',\n",
              " 'Mehlis',\n",
              " 'is',\n",
              " 'to',\n",
              " 'return',\n",
              " 'to',\n",
              " 'Damascus',\n",
              " 'to',\n",
              " 'interview',\n",
              " 'several',\n",
              " 'Syrian',\n",
              " 'officials',\n",
              " 'about',\n",
              " 'the',\n",
              " 'assassination',\n",
              " '.',\n",
              " 'The',\n",
              " 'global',\n",
              " 'financial',\n",
              " 'crisis',\n",
              " 'has',\n",
              " 'left',\n",
              " 'Iceland',\n",
              " \"'s\",\n",
              " 'economy',\n",
              " 'in',\n",
              " 'shambles',\n",
              " '.',\n",
              " 'Israeli',\n",
              " 'officials',\n",
              " 'say',\n",
              " 'Prime',\n",
              " 'Minister',\n",
              " 'Ariel',\n",
              " 'Sharon',\n",
              " 'will',\n",
              " 'undergo',\n",
              " 'a',\n",
              " 'medical',\n",
              " 'procedure',\n",
              " 'Thursday',\n",
              " 'to',\n",
              " 'close',\n",
              " 'a',\n",
              " 'tiny',\n",
              " 'hole',\n",
              " 'in',\n",
              " 'his',\n",
              " 'heart',\n",
              " 'discovered',\n",
              " 'during',\n",
              " 'treatment',\n",
              " 'for',\n",
              " 'a',\n",
              " 'minor',\n",
              " 'stroke',\n",
              " 'suffered',\n",
              " 'last',\n",
              " 'month',\n",
              " '.',\n",
              " 'Doctors',\n",
              " 'describe',\n",
              " 'the',\n",
              " 'tiny',\n",
              " 'hole',\n",
              " 'as',\n",
              " 'a',\n",
              " 'minor',\n",
              " 'birth',\n",
              " 'defect',\n",
              " 'and',\n",
              " 'say',\n",
              " 'it',\n",
              " 'is',\n",
              " 'in',\n",
              " 'the',\n",
              " 'partition',\n",
              " 'between',\n",
              " 'the',\n",
              " 'upper',\n",
              " 'chambers',\n",
              " 'of',\n",
              " 'Mr.',\n",
              " 'Sharon',\n",
              " \"'s\",\n",
              " 'heart',\n",
              " '.',\n",
              " 'The',\n",
              " 'procedure',\n",
              " ',',\n",
              " 'known',\n",
              " 'as',\n",
              " 'cardiac',\n",
              " 'catheterization',\n",
              " ',',\n",
              " 'involves',\n",
              " 'inserting',\n",
              " 'a',\n",
              " 'catheter',\n",
              " 'through',\n",
              " 'a',\n",
              " 'blood',\n",
              " 'vessel',\n",
              " 'into',\n",
              " 'the',\n",
              " 'heart',\n",
              " ',',\n",
              " 'where',\n",
              " 'an',\n",
              " 'umbrella-like',\n",
              " 'device',\n",
              " 'will',\n",
              " 'plug',\n",
              " 'the',\n",
              " 'hole',\n",
              " '.',\n",
              " 'Doctors',\n",
              " 'say',\n",
              " 'they',\n",
              " 'expect',\n",
              " 'Mr.',\n",
              " 'Sharon',\n",
              " 'will',\n",
              " 'make',\n",
              " 'a',\n",
              " 'full',\n",
              " 'recovery',\n",
              " '.',\n",
              " 'Mr.',\n",
              " 'Sharon',\n",
              " 'returned',\n",
              " 'to',\n",
              " 'work',\n",
              " 'on',\n",
              " 'December',\n",
              " '25',\n",
              " ',',\n",
              " 'one',\n",
              " 'week',\n",
              " 'after',\n",
              " 'his',\n",
              " 'emergency',\n",
              " 'hospitalization',\n",
              " '.',\n",
              " 'Doctors',\n",
              " 'say',\n",
              " 'the',\n",
              " 'stroke',\n",
              " 'has',\n",
              " 'not',\n",
              " 'caused',\n",
              " 'any',\n",
              " 'permanent',\n",
              " 'damage',\n",
              " '.',\n",
              " 'The',\n",
              " 'designers',\n",
              " 'of',\n",
              " 'the',\n",
              " 'first',\n",
              " 'private',\n",
              " 'manned',\n",
              " 'rocket',\n",
              " 'to',\n",
              " 'burst',\n",
              " 'into',\n",
              " 'space',\n",
              " 'have',\n",
              " 'received',\n",
              " 'a',\n",
              " '$',\n",
              " '10',\n",
              " 'million',\n",
              " 'prize',\n",
              " 'created',\n",
              " 'to',\n",
              " 'promote',\n",
              " 'space',\n",
              " 'tourism',\n",
              " '.',\n",
              " 'SpaceShipOne',\n",
              " 'designer',\n",
              " 'Burt',\n",
              " 'Rutan',\n",
              " 'accepted',\n",
              " 'the',\n",
              " 'Ansari',\n",
              " 'X',\n",
              " 'Prize',\n",
              " 'money',\n",
              " 'and',\n",
              " 'a',\n",
              " 'trophy',\n",
              " 'on',\n",
              " 'behalf',\n",
              " 'of',\n",
              " 'his',\n",
              " 'team',\n",
              " 'Saturday',\n",
              " 'during',\n",
              " 'an',\n",
              " 'awards',\n",
              " 'ceremony',\n",
              " 'in',\n",
              " 'the',\n",
              " 'U.S.',\n",
              " 'state',\n",
              " 'of',\n",
              " 'Missouri',\n",
              " '.',\n",
              " 'To',\n",
              " 'win',\n",
              " 'the',\n",
              " 'money',\n",
              " ',',\n",
              " 'SpaceShipOne',\n",
              " 'had',\n",
              " 'to',\n",
              " 'blast',\n",
              " 'off',\n",
              " 'into',\n",
              " 'space',\n",
              " 'twice',\n",
              " 'in',\n",
              " 'a',\n",
              " 'two-week',\n",
              " 'period',\n",
              " 'and',\n",
              " 'fly',\n",
              " 'at',\n",
              " 'least',\n",
              " '100',\n",
              " 'kilometers',\n",
              " 'above',\n",
              " 'Earth',\n",
              " '.',\n",
              " 'The',\n",
              " 'spacecraft',\n",
              " 'made',\n",
              " 'its',\n",
              " 'flights',\n",
              " 'in',\n",
              " 'late',\n",
              " 'September',\n",
              " 'and',\n",
              " 'early',\n",
              " 'October',\n",
              " ',',\n",
              " 'lifting',\n",
              " 'off',\n",
              " 'from',\n",
              " 'California',\n",
              " \"'s\",\n",
              " 'Mojave',\n",
              " 'desert',\n",
              " '.',\n",
              " 'Three',\n",
              " 'major',\n",
              " 'banks',\n",
              " 'have',\n",
              " 'collapsed',\n",
              " ',',\n",
              " 'unemployment',\n",
              " 'has',\n",
              " 'soared',\n",
              " ',',\n",
              " 'and',\n",
              " 'the',\n",
              " 'value',\n",
              " 'of',\n",
              " 'the',\n",
              " 'krona',\n",
              " 'has',\n",
              " 'plunged',\n",
              " '.',\n",
              " 'The',\n",
              " 'vehicle',\n",
              " 'had',\n",
              " 'to',\n",
              " 'carry',\n",
              " 'a',\n",
              " 'pilot',\n",
              " 'and',\n",
              " 'weight',\n",
              " 'equivalent',\n",
              " 'to',\n",
              " 'two',\n",
              " 'passengers',\n",
              " '.',\n",
              " 'SpaceShipOne',\n",
              " 'was',\n",
              " 'financed',\n",
              " 'with',\n",
              " 'more',\n",
              " 'than',\n",
              " '$',\n",
              " '20',\n",
              " 'million',\n",
              " 'from',\n",
              " 'Paul',\n",
              " 'Allen',\n",
              " ',',\n",
              " 'a',\n",
              " 'co-founder',\n",
              " 'of',\n",
              " 'the',\n",
              " 'Microsoft',\n",
              " 'Corporation',\n",
              " '.',\n",
              " 'North',\n",
              " 'Korea',\n",
              " 'says',\n",
              " 'flooding',\n",
              " 'caused',\n",
              " 'by',\n",
              " 'last',\n",
              " 'week',\n",
              " \"'s\",\n",
              " 'typhoon',\n",
              " ',',\n",
              " 'Wipha',\n",
              " ',',\n",
              " 'has',\n",
              " 'destroyed',\n",
              " '14,000',\n",
              " 'homes',\n",
              " 'and',\n",
              " '1,09,000',\n",
              " 'hectares',\n",
              " 'of',\n",
              " 'crops',\n",
              " '.',\n",
              " 'The',\n",
              " 'state',\n",
              " 'news',\n",
              " 'agency',\n",
              " 'KCNA',\n",
              " 'reported',\n",
              " 'the',\n",
              " 'damage',\n",
              " 'Monday',\n",
              " '.',\n",
              " 'It',\n",
              " 'says',\n",
              " 'the',\n",
              " 'floods',\n",
              " 'also',\n",
              " 'destroyed',\n",
              " 'or',\n",
              " 'damaged',\n",
              " '8,000',\n",
              " 'public',\n",
              " 'buildings',\n",
              " 'and',\n",
              " 'washed',\n",
              " 'out',\n",
              " 'roads',\n",
              " ',',\n",
              " 'bridges',\n",
              " 'and',\n",
              " 'railways',\n",
              " '.',\n",
              " 'The',\n",
              " 'report',\n",
              " 'did',\n",
              " 'not',\n",
              " 'mention',\n",
              " 'any',\n",
              " 'deaths',\n",
              " 'or',\n",
              " 'injuries',\n",
              " '.',\n",
              " 'Most',\n",
              " 'of',\n",
              " 'the',\n",
              " 'heavy',\n",
              " 'rains',\n",
              " 'and',\n",
              " 'flooding',\n",
              " 'occurred',\n",
              " 'in',\n",
              " 'the',\n",
              " 'southwestern',\n",
              " 'part',\n",
              " 'of',\n",
              " 'the',\n",
              " 'country',\n",
              " ',',\n",
              " 'including',\n",
              " 'the',\n",
              " 'capital',\n",
              " ',',\n",
              " 'Pyongyang',\n",
              " '.',\n",
              " 'Last',\n",
              " 'month',\n",
              " ',',\n",
              " 'severe',\n",
              " 'flooding',\n",
              " 'in',\n",
              " 'North',\n",
              " 'Korea',\n",
              " 'left',\n",
              " '600',\n",
              " 'people',\n",
              " 'dead',\n",
              " 'or',\n",
              " 'missing',\n",
              " ',',\n",
              " 'and',\n",
              " 'displaced',\n",
              " 'more',\n",
              " 'than',\n",
              " '1,00,000',\n",
              " 'others',\n",
              " '.',\n",
              " 'A',\n",
              " 'strong',\n",
              " 'earthquake',\n",
              " 'under',\n",
              " 'the',\n",
              " 'ocean',\n",
              " 'off',\n",
              " 'Indonesia',\n",
              " \"'s\",\n",
              " 'Sumatra',\n",
              " 'and',\n",
              " 'Nias',\n",
              " 'islands',\n",
              " 'has',\n",
              " 'caused',\n",
              " 'some',\n",
              " 'panic',\n",
              " 'but',\n",
              " 'no',\n",
              " 'damage',\n",
              " 'or',\n",
              " 'injuries',\n",
              " '.',\n",
              " 'The',\n",
              " 'U.S.',\n",
              " 'Geological',\n",
              " 'Survey',\n",
              " 'gave',\n",
              " 'a',\n",
              " 'preliminary',\n",
              " 'estimate',\n",
              " 'of',\n",
              " 'the',\n",
              " 'strength',\n",
              " 'of',\n",
              " 'the',\n",
              " 'Tuesday',\n",
              " 'morning',\n",
              " 'quake',\n",
              " 'at',\n",
              " '6.7',\n",
              " 'on',\n",
              " 'the',\n",
              " 'Richter',\n",
              " 'scale',\n",
              " ',',\n",
              " 'and',\n",
              " 'said',\n",
              " 'the',\n",
              " 'epicenter',\n",
              " 'was',\n",
              " 'close',\n",
              " 'to',\n",
              " 'the',\n",
              " 'island',\n",
              " 'of',\n",
              " 'Nias',\n",
              " '.',\n",
              " 'Prime',\n",
              " 'Minister',\n",
              " 'Geir',\n",
              " 'Haarde',\n",
              " 'has',\n",
              " 'refused',\n",
              " 'to',\n",
              " 'resign',\n",
              " 'or',\n",
              " 'call',\n",
              " 'for',\n",
              " 'early',\n",
              " 'elections',\n",
              " '.',\n",
              " 'The',\n",
              " 'quake',\n",
              " 'did',\n",
              " 'not',\n",
              " 'cause',\n",
              " 'a',\n",
              " 'tsunami',\n",
              " '.',\n",
              " 'An',\n",
              " 'earthquake',\n",
              " 'in',\n",
              " 'late',\n",
              " 'March',\n",
              " 'killed',\n",
              " 'more',\n",
              " 'than',\n",
              " '900',\n",
              " 'people',\n",
              " 'on',\n",
              " 'Nias',\n",
              " '.',\n",
              " 'Both',\n",
              " 'Sumatra',\n",
              " 'and',\n",
              " 'Nias',\n",
              " 'have',\n",
              " 'experienced',\n",
              " 'countless',\n",
              " 'earthquakes',\n",
              " 'since',\n",
              " 'a',\n",
              " 'massive',\n",
              " 'tsunami-producing',\n",
              " 'quake',\n",
              " 'on',\n",
              " 'December',\n",
              " '26',\n",
              " '.',\n",
              " 'The',\n",
              " 'latest',\n",
              " 'official',\n",
              " 'death',\n",
              " 'toll',\n",
              " 'from',\n",
              " 'that',\n",
              " 'tragedy',\n",
              " 'stands',\n",
              " 'at',\n",
              " 'some',\n",
              " '1,76,000',\n",
              " 'people',\n",
              " 'killed',\n",
              " '-',\n",
              " '1,28,000',\n",
              " 'of',\n",
              " 'them',\n",
              " 'in',\n",
              " 'Indonesia',\n",
              " '.',\n",
              " 'Nearly',\n",
              " '50,000',\n",
              " 'people',\n",
              " 'are',\n",
              " 'still',\n",
              " 'listed',\n",
              " 'as',\n",
              " 'missing',\n",
              " ',',\n",
              " 'but',\n",
              " 'most',\n",
              " 'of',\n",
              " 'them',\n",
              " 'are',\n",
              " 'feared',\n",
              " 'dead',\n",
              " '.',\n",
              " 'The',\n",
              " 'U.S.',\n",
              " 'rap',\n",
              " 'star',\n",
              " 'Snoop',\n",
              " 'Dogg',\n",
              " 'and',\n",
              " 'five',\n",
              " 'of',\n",
              " 'his',\n",
              " 'associates',\n",
              " 'have',\n",
              " 'been',\n",
              " 'arrested',\n",
              " 'in',\n",
              " 'Britain',\n",
              " 'after',\n",
              " 'a',\n",
              " 'disturbance',\n",
              " 'at',\n",
              " 'London',\n",
              " \"'s\",\n",
              " 'Heathrow',\n",
              " 'Airport',\n",
              " '.',\n",
              " 'Police',\n",
              " 'told',\n",
              " 'British',\n",
              " 'media',\n",
              " 'that',\n",
              " 'the',\n",
              " 'musician',\n",
              " ',',\n",
              " 'who',\n",
              " 'was',\n",
              " 'born',\n",
              " 'with',\n",
              " 'the',\n",
              " 'name',\n",
              " 'Calvin',\n",
              " 'Broadus',\n",
              " ',',\n",
              " 'and',\n",
              " 'members',\n",
              " 'of',\n",
              " 'his',\n",
              " 'entourage',\n",
              " 'were',\n",
              " 'being',\n",
              " 'held',\n",
              " 'on',\n",
              " 'charges',\n",
              " 'of',\n",
              " '\"',\n",
              " 'violent',\n",
              " 'disorder',\n",
              " 'and',\n",
              " 'affray',\n",
              " '.',\n",
              " '\"',\n",
              " 'The',\n",
              " 'group',\n",
              " 'was',\n",
              " 'waiting',\n",
              " 'for',\n",
              " 'a',\n",
              " 'flight',\n",
              " 'to',\n",
              " 'South',\n",
              " 'Africa',\n",
              " ',',\n",
              " 'where',\n",
              " 'Snoop',\n",
              " 'Dogg',\n",
              " 'was',\n",
              " 'to',\n",
              " 'perform',\n",
              " 'in',\n",
              " 'a',\n",
              " 'concert',\n",
              " 'Thursday',\n",
              " ',',\n",
              " 'when',\n",
              " 'it',\n",
              " 'was',\n",
              " 'denied',\n",
              " 'access',\n",
              " 'to',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ],
      "source": [
        "all_tokens = [token for row in df['Word'] for token in row]\n",
        "all_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "CHbiD1GZHcuv"
      },
      "outputs": [],
      "source": [
        "vocab = {token: idx+1 for idx, token in enumerate(sorted(set(all_tokens)))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "XLAZzKzNHe0m"
      },
      "outputs": [],
      "source": [
        "vocab_size=len(vocab)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQxnoBfbHqxd",
        "outputId": "3355f0d4-b384-4ee0-ac69-6578b833df93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35179"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ],
      "source": [
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z4xNATUq6xGo"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "QbmB0LfLD0IX"
      },
      "outputs": [],
      "source": [
        "def tokens_to_ids(token_list, vocab):\n",
        "    return [vocab.get(token, 0) for token in token_list]\n",
        "\n",
        "token_ids = tokens_to_ids(all_tokens, vocab)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['token_ids'] = df['Word'].apply(lambda tokens: tokens_to_ids(tokens, vocab))"
      ],
      "metadata": {
        "id": "Y31INkJJ63mr"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['token_ids']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "b7Rows6G6wb-",
        "outputId": "6d01d68a-32fd-44c3-cbcf-83a1004cba72"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [15078, 27701, 20970, 24219, 26435, 33390, 968...\n",
              "1        [8194, 27728, 31034, 33290, 22578, 33465, 2372...\n",
              "2        [7599, 24040, 13560, 28906, 26766, 24371, 2485...\n",
              "3        [15050, 25893, 16916, 16575, 33180, 24593, 323...\n",
              "4        [15425, 30228, 20255, 8421, 5853, 30958, 14608...\n",
              "                               ...                        \n",
              "47954    [11663, 25852, 10573, 7809, 10792, 24198, 3095...\n",
              "47955    [11627, 15091, 22, 8194, 32336, 26571, 29457, ...\n",
              "47956    [6522, 8189, 18, 21474, 8681, 316, 22006, 22, ...\n",
              "47957    [14090, 33260, 22, 17933, 24219, 24317, 29446,...\n",
              "47958    [15030, 15606, 11147, 25446, 28936, 33247, 343...\n",
              "Name: token_ids, Length: 47959, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[15078, 27701, 20970, 24219, 26435, 33390, 968...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[8194, 27728, 31034, 33290, 22578, 33465, 2372...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[7599, 24040, 13560, 28906, 26766, 24371, 2485...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[15050, 25893, 16916, 16575, 33180, 24593, 323...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[15425, 30228, 20255, 8421, 5853, 30958, 14608...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47954</th>\n",
              "      <td>[11663, 25852, 10573, 7809, 10792, 24198, 3095...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47955</th>\n",
              "      <td>[11627, 15091, 22, 8194, 32336, 26571, 29457, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47956</th>\n",
              "      <td>[6522, 8189, 18, 21474, 8681, 316, 22006, 22, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47957</th>\n",
              "      <td>[14090, 33260, 22, 17933, 24219, 24317, 29446,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47958</th>\n",
              "      <td>[15030, 15606, 11147, 25446, 28936, 33247, 343...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47959 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tag token id cevirmeliyik"
      ],
      "metadata": {
        "id": "oy0doKHd3sjB"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Tag'].dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gqHjlsL5UMq",
        "outputId": "80404b80-8235-43e5-810c-05ac260815d8"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "df['Tag'] = df['Tag'].apply(ast.literal_eval)\n"
      ],
      "metadata": {
        "id": "sw4gea_y5xlY"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#uniques for POS\n",
        "uniques_pos=sorted(df['POS'].explode().unique())\n",
        "pos2id={pos: idx for idx,pos in enumerate(uniques_pos)}\n",
        "id2pos={idx: pos for pos,idx in pos2id.items()}"
      ],
      "metadata": {
        "id": "n7tvOGAKsHti"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uniques_tag=sorted(df['Tag'].explode().unique())\n",
        "uniques_tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg_QCfxp4tRj",
        "outputId": "41956d5d-e20a-45b4-bae6-95f95b51f47a"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-art',\n",
              " 'B-eve',\n",
              " 'B-geo',\n",
              " 'B-gpe',\n",
              " 'B-nat',\n",
              " 'B-org',\n",
              " 'B-per',\n",
              " 'B-tim',\n",
              " 'I-art',\n",
              " 'I-eve',\n",
              " 'I-geo',\n",
              " 'I-gpe',\n",
              " 'I-nat',\n",
              " 'I-org',\n",
              " 'I-per',\n",
              " 'I-tim',\n",
              " 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag2id = {tag: idx for idx, tag in enumerate(uniques_tag)}\n",
        "id2tag = {idx: tag for tag, idx in tag2id.items()}"
      ],
      "metadata": {
        "id": "aH9P77Fs6CJg"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OILCFxcg6OCH",
        "outputId": "edcd2b3a-e4fc-4853-eec8-ccc4329353da"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-art': 0,\n",
              " 'B-eve': 1,\n",
              " 'B-geo': 2,\n",
              " 'B-gpe': 3,\n",
              " 'B-nat': 4,\n",
              " 'B-org': 5,\n",
              " 'B-per': 6,\n",
              " 'B-tim': 7,\n",
              " 'I-art': 8,\n",
              " 'I-eve': 9,\n",
              " 'I-geo': 10,\n",
              " 'I-gpe': 11,\n",
              " 'I-nat': 12,\n",
              " 'I-org': 13,\n",
              " 'I-per': 14,\n",
              " 'I-tim': 15,\n",
              " 'O': 16}"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnIgHEGU6P2w",
        "outputId": "4ba12c43-8c73-4d38-ae3d-936a89e7715c"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'B-art',\n",
              " 1: 'B-eve',\n",
              " 2: 'B-geo',\n",
              " 3: 'B-gpe',\n",
              " 4: 'B-nat',\n",
              " 5: 'B-org',\n",
              " 6: 'B-per',\n",
              " 7: 'B-tim',\n",
              " 8: 'I-art',\n",
              " 9: 'I-eve',\n",
              " 10: 'I-geo',\n",
              " 11: 'I-gpe',\n",
              " 12: 'I-nat',\n",
              " 13: 'I-org',\n",
              " 14: 'I-per',\n",
              " 15: 'I-tim',\n",
              " 16: 'O'}"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['tag_ids'] = df['Tag'].apply(lambda tags: [tag2id[tag] for tag in tags])"
      ],
      "metadata": {
        "id": "3MvX_NKC6REp"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['pos_ids']  = df['POS'].apply(lambda tags: [pos2id[tag] for tag in tags])"
      ],
      "metadata": {
        "id": "3Gsmg3F_spNV"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tag_ids']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "TEIX0yBo6iXh",
        "outputId": "de3385f5-7ff3-4171-cfb7-2c8072a647e6"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [16, 16, 16, 16, 16, 16, 2, 16, 16, 16, 16, 16...\n",
              "1        [3, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16...\n",
              "2        [16, 16, 7, 16, 16, 16, 16, 16, 2, 16, 16, 16,...\n",
              "3             [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
              "4        [2, 16, 16, 6, 14, 16, 7, 16, 2, 16, 3, 16, 3,...\n",
              "                               ...                        \n",
              "47954    [16, 16, 16, 6, 14, 16, 16, 16, 16, 16, 16, 16...\n",
              "47955    [16, 7, 16, 3, 16, 16, 16, 16, 16, 16, 16, 16,...\n",
              "47956    [16, 2, 16, 16, 7, 15, 16, 16, 16, 16, 16, 16,...\n",
              "47957    [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 1...\n",
              "47958    [16, 5, 13, 16, 16, 16, 16, 16, 16, 16, 16, 16...\n",
              "Name: tag_ids, Length: 47959, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tag_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[16, 16, 16, 16, 16, 16, 2, 16, 16, 16, 16, 16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[3, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[16, 16, 7, 16, 16, 16, 16, 16, 2, 16, 16, 16,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[2, 16, 16, 6, 14, 16, 7, 16, 2, 16, 3, 16, 3,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47954</th>\n",
              "      <td>[16, 16, 16, 6, 14, 16, 16, 16, 16, 16, 16, 16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47955</th>\n",
              "      <td>[16, 7, 16, 3, 16, 16, 16, 16, 16, 16, 16, 16,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47956</th>\n",
              "      <td>[16, 2, 16, 16, 7, 15, 16, 16, 16, 16, 16, 16,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47957</th>\n",
              "      <td>[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47958</th>\n",
              "      <td>[16, 5, 13, 16, 16, 16, 16, 16, 16, 16, 16, 16...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47959 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Indi Token id leri paddin etmek lazimdiki hem imput hem output uzunlugu eyni olsun"
      ],
      "metadata": {
        "id": "u2aNJfp17EpJ"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "cZT7h9eT7dDd"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['seq_len'] = df['token_ids'].apply(len)\n",
        "\n",
        "print(\"Max Length:\", df['seq_len'].max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIyDKmUk7uIF",
        "outputId": "afbe716f-620c-4b69-ab43-33f902a6d855"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Length: 104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = int(df['seq_len'].quantile(0.95))"
      ],
      "metadata": {
        "id": "vCns2Qco70rw"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7MBAvAM72PK",
        "outputId": "33d01be3-585d-4716-dc36-44966abc5ed5"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pos2id.keys())"
      ],
      "metadata": {
        "id": "nZsNhNkKuXUI",
        "outputId": "b5baab19-36a9-47b4-d639-72ed22d4c309",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['$', ',', '.', ':', ';', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LRB', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'RRB', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LEN = 35\n",
        "\n",
        "df['input_ids'] = list(pad_sequences(df['token_ids'], maxlen=MAX_LEN, padding='post', value=0))\n",
        "df['label_ids'] = list(pad_sequences(df['tag_ids'], maxlen=MAX_LEN, padding='post', value=tag2id['O']))\n",
        "\n",
        "# pos ucun padding\n",
        "df['pos_label_ids']=list(pad_sequences(df['pos_ids'], maxlen=MAX_LEN, padding='post',value=pos2id['NN']))\n"
      ],
      "metadata": {
        "id": "OVdhOO_87K20"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['input_ids']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "kqFz8zSL7791",
        "outputId": "59a44871-9727-4a5c-ab1f-ba892e3f6550"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [15078, 27701, 20970, 24219, 26435, 33390, 968...\n",
              "1        [8194, 27728, 31034, 33290, 22578, 33465, 2372...\n",
              "2        [7599, 24040, 13560, 28906, 26766, 24371, 2485...\n",
              "3        [15050, 25893, 16916, 16575, 33180, 24593, 323...\n",
              "4        [15425, 30228, 20255, 8421, 5853, 30958, 14608...\n",
              "                               ...                        \n",
              "47954    [11663, 25852, 10573, 7809, 10792, 24198, 3095...\n",
              "47955    [11627, 15091, 22, 8194, 32336, 26571, 29457, ...\n",
              "47956    [6522, 8189, 18, 21474, 8681, 316, 22006, 22, ...\n",
              "47957    [14090, 33260, 22, 17933, 24219, 24317, 29446,...\n",
              "47958    [15030, 15606, 11147, 25446, 28936, 33247, 343...\n",
              "Name: input_ids, Length: 47959, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[15078, 27701, 20970, 24219, 26435, 33390, 968...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[8194, 27728, 31034, 33290, 22578, 33465, 2372...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[7599, 24040, 13560, 28906, 26766, 24371, 2485...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[15050, 25893, 16916, 16575, 33180, 24593, 323...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[15425, 30228, 20255, 8421, 5853, 30958, 14608...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47954</th>\n",
              "      <td>[11663, 25852, 10573, 7809, 10792, 24198, 3095...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47955</th>\n",
              "      <td>[11627, 15091, 22, 8194, 32336, 26571, 29457, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47956</th>\n",
              "      <td>[6522, 8189, 18, 21474, 8681, 316, 22006, 22, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47957</th>\n",
              "      <td>[14090, 33260, 22, 17933, 24219, 24317, 29446,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47958</th>\n",
              "      <td>[15030, 15606, 11147, 25446, 28936, 33247, 343...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47959 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label_ids']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "o4XF204e7-6P",
        "outputId": "c90d84c0-bc4c-47a0-f94d-8a73abe46d78"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [16, 16, 16, 16, 16, 16, 2, 16, 16, 16, 16, 16...\n",
              "1        [3, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16...\n",
              "2        [16, 16, 7, 16, 16, 16, 16, 16, 2, 16, 16, 16,...\n",
              "3        [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 1...\n",
              "4        [2, 16, 16, 6, 14, 16, 7, 16, 2, 16, 3, 16, 3,...\n",
              "                               ...                        \n",
              "47954    [16, 16, 16, 6, 14, 16, 16, 16, 16, 16, 16, 16...\n",
              "47955    [16, 7, 16, 3, 16, 16, 16, 16, 16, 16, 16, 16,...\n",
              "47956    [16, 2, 16, 16, 7, 15, 16, 16, 16, 16, 16, 16,...\n",
              "47957    [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 1...\n",
              "47958    [16, 5, 13, 16, 16, 16, 16, 16, 16, 16, 16, 16...\n",
              "Name: label_ids, Length: 47959, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[16, 16, 16, 16, 16, 16, 2, 16, 16, 16, 16, 16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[3, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[16, 16, 7, 16, 16, 16, 16, 16, 2, 16, 16, 16,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[2, 16, 16, 6, 14, 16, 7, 16, 2, 16, 3, 16, 3,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47954</th>\n",
              "      <td>[16, 16, 16, 6, 14, 16, 16, 16, 16, 16, 16, 16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47955</th>\n",
              "      <td>[16, 7, 16, 3, 16, 16, 16, 16, 16, 16, 16, 16,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47956</th>\n",
              "      <td>[16, 2, 16, 16, 7, 15, 16, 16, 16, 16, 16, 16,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47957</th>\n",
              "      <td>[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47958</th>\n",
              "      <td>[16, 5, 13, 16, 16, 16, 16, 16, 16, 16, 16, 16...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47959 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['pos_label_ids']"
      ],
      "metadata": {
        "id": "RrF7scgIvfva",
        "outputId": "d7a12d39-01ea-4d18-8b6a-72464eedd015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [19, 10, 19, 35, 34, 10, 17, 29, 31, 7, 16, 10...\n",
              "1        [11, 19, 35, 22, 35, 29, 31, 16, 29, 11, 11, 1...\n",
              "2        [16, 19, 17, 32, 11, 19, 10, 7, 17, 11, 16, 1,...\n",
              "3        [22, 32, 10, 7, 16, 11, 16, 10, 16, 19, 2, 16,...\n",
              "4        [17, 16, 16, 17, 17, 32, 17, 1, 17, 1, 11, 5, ...\n",
              "                               ...                        \n",
              "47954    [17, 16, 17, 17, 17, 36, 34, 22, 36, 29, 31, 5...\n",
              "47955    [10, 17, 1, 11, 16, 19, 34, 7, 16, 10, 7, 11, ...\n",
              "47956    [33, 17, 21, 11, 17, 6, 19, 1, 19, 19, 32, 19,...\n",
              "47957    [10, 24, 1, 19, 35, 34, 11, 19, 10, 7, 34, 5, ...\n",
              "47958    [7, 17, 17, 36, 33, 7, 16, 10, 11, 19, 29, 31,...\n",
              "Name: pos_label_ids, Length: 47959, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pos_label_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[19, 10, 19, 35, 34, 10, 17, 29, 31, 7, 16, 10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[11, 19, 35, 22, 35, 29, 31, 16, 29, 11, 11, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[16, 19, 17, 32, 11, 19, 10, 7, 17, 11, 16, 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[22, 32, 10, 7, 16, 11, 16, 10, 16, 19, 2, 16,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[17, 16, 16, 17, 17, 32, 17, 1, 17, 1, 11, 5, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47954</th>\n",
              "      <td>[17, 16, 17, 17, 17, 36, 34, 22, 36, 29, 31, 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47955</th>\n",
              "      <td>[10, 17, 1, 11, 16, 19, 34, 7, 16, 10, 7, 11, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47956</th>\n",
              "      <td>[33, 17, 21, 11, 17, 6, 19, 1, 19, 19, 32, 19,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47957</th>\n",
              "      <td>[10, 24, 1, 19, 35, 34, 11, 19, 10, 7, 34, 5, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47958</th>\n",
              "      <td>[7, 17, 17, 36, 33, 7, 16, 10, 11, 19, 29, 31,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47959 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train teste bolek demeli hem POS ucun Hem de NER ucun ayri ayri output olmalidi multi Task ucun ona gore y hissesini y_ner ve\n",
        "# y_pos kimi ayirdiqdan sonra train_test_split istifade edecem"
      ],
      "metadata": {
        "id": "hj1o1uhB8HxL"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = np.array(df['input_ids'].to_list(),dtype=np.int32)\n",
        "y_ner = np.array(df['label_ids'].to_list(),dtype=np.int32)\n",
        "y_pos=np.array(df['pos_label_ids'].to_list(), dtype=np.int32)\n",
        "\n",
        "# Pozitional ID-lər (0, 1, 2, ..., MAX_LEN-1)\n",
        "pos_ids = np.tile(np.arange(X.shape[1]), (X.shape[0], 1))\n",
        "\n",
        "X_train, X_test, y_ner_train, y_ner_test, y_pos_train, y_pos_test, pos_train, pos_test = train_test_split(\n",
        "    X, y_ner, y_pos, pos_ids, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "Mi1zPs9V8Kjf"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape[0], y_ner.shape[0], y_pos.shape[0], pos_ids.shape[0]"
      ],
      "metadata": {
        "id": "IMSNfdTjxmFl",
        "outputId": "da09d40c-c03a-40ee-c4c7-08208f4c953f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47959, 47959, 47959, 47959)"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X dtype:\", X.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xoI5SwBP20G",
        "outputId": "27db245b-d7cb-48aa-ff95-f7010b1a17d9"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X dtype: int32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow datasina cevirek"
      ],
      "metadata": {
        "id": "vhKoxeig8V2B"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    ((X_train, pos_train), (y_ner_train, y_pos_train))\n",
        ").batch(batch_size).shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    ((X_test, pos_test), (y_ner_test, y_pos_test))\n",
        ").batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "rCbMxHeY8ZUj"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI8PWEdS82so",
        "outputId": "f60be7bb-440b-4ef0-8eec-f493712bd09f"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=((TensorSpec(shape=(None, 35), dtype=tf.int32, name=None), TensorSpec(shape=(None, 35), dtype=tf.int64, name=None)), (TensorSpec(shape=(None, 35), dtype=tf.int32, name=None), TensorSpec(shape=(None, 35), dtype=tf.int32, name=None)))>"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5WOOM7f85J8",
        "outputId": "a6576b80-bf58-47b8-912e-923ed0388dac"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=((TensorSpec(shape=(None, 35), dtype=tf.int32, name=None), TensorSpec(shape=(None, 35), dtype=tf.int64, name=None)), (TensorSpec(shape=(None, 35), dtype=tf.int32, name=None), TensorSpec(shape=(None, 35), dtype=tf.int32, name=None)))>"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoder base transformer model\n",
        "\n",
        "encoder_inputs=tf.keras.Input(shape=[None,], name='encoder_inputs')\n",
        "\n",
        "# encoder ama bu defe POS ucu\n",
        "pos_encoder_inputs=tf.keras.Input(shape=[None,], name='pos_encoder_inputs')\n",
        "\n",
        "#Embedding layer\n",
        "embed_layer=tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=128, mask_zero=True, name='embed_layer')\n",
        "\n",
        "# Same Pos ucun emdedding layer\n",
        "pos_em_lay=tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=128,mask_zero=True, name='pos_em_layer')\n",
        "\n",
        "#encoder embedding\n",
        "encoder_embed=embed_layer(encoder_inputs)\n",
        "pos_encoder_embed=pos_em_lay(pos_encoder_inputs)\n",
        "sum_pos_and_input_embed=encoder_embed+pos_encoder_embed\n",
        "\n",
        "\n",
        "#Positional embed layer\n",
        "embed_size=128\n",
        "pos_embed_layer=tf.keras.layers.Embedding(MAX_LEN, embed_size)\n",
        "\n",
        "pos_encoder=tf.keras.layers.Lambda(lambda x: tf.range(start=0,limit=tf.shape(x)[1],\n",
        "                                                            delta=1))(encoder_inputs)\n",
        "\n",
        "positional_embedding=pos_embed_layer(pos_encoder)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#concat tokrn and positional embedding\n",
        "encoder_embedding=positional_embedding+sum_pos_and_input_embed\n",
        "\n",
        "#Add multihead attentioan layer\n",
        "\n",
        "num_heads=3\n",
        "encoder_attention=tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_size)(encoder_embedding,encoder_embedding)\n",
        "encoder_attention=tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoder_attention+encoder_embedding)\n",
        "\n",
        "\n",
        "# add Feed Forward (Dense) layer\n",
        "ff_dim=512\n",
        "encoder_ff=tf.keras.layers.Dense(ff_dim, activation='relu')(encoder_attention)\n",
        "encoder_ff=tf.keras.layers.Dense(embed_size)(encoder_ff)\n",
        "encoder_ff=tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoder_ff+encoder_attention)\n",
        "\n",
        "\n",
        "#Add output layer Multi task olduguna gore hem Ner ucun Hem POS ucun ayri ayri output yazmaliyiq\n",
        "ner_output=tf.keras.layers.Dense(len(tag2id), activation='softmax', name='ner_output')(encoder_ff)\n",
        "\n",
        "pos_output=tf.keras.layers.Dense(len(pos2id), activation='softmax', name='pos_output')(encoder_ff)"
      ],
      "metadata": {
        "id": "6XyiBaVs861T"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Callback and learning schedule\n",
        "learning_rate_schedule=tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=1000,\n",
        "    decay_rate=0.9\n",
        ")\n",
        "\n",
        "early_stopping=tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "zkHz26kylJfS"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make model\n",
        "model=tf.keras.Model(inputs=[encoder_inputs,pos_encoder_inputs], outputs=[ner_output, pos_output])"
      ],
      "metadata": {
        "id": "BRNWUvaY_R2a"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_schedule)"
      ],
      "metadata": {
        "id": "BDCOjhnzl5Me"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model compiling\n",
        "model.compile(optimizer=optimizer,\n",
        "\n",
        "              loss= {'ner_output': 'sparse_categorical_crossentropy',\n",
        "                    'pos_output': 'sparse_categorical_crossentropy' },\n",
        "\n",
        "               metrics={\n",
        "        'ner_output': 'accuracy',\n",
        "        'pos_output': 'accuracy'}\n",
        "    )"
      ],
      "metadata": {
        "id": "hojie7gcSnGj"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model fitting\n",
        "model.fit(train_dataset, validation_data=valid_dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS1FPR3nBfH8",
        "outputId": "0f1baf8d-63bc-4154-f840-6afc6eaec221"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 0.5653 - ner_output_accuracy: 0.9485 - ner_output_loss: 0.2162 - pos_output_accuracy: 0.9045 - pos_output_loss: 0.3491 - val_loss: 0.1913 - val_ner_output_accuracy: 0.9692 - val_ner_output_loss: 0.1023 - val_pos_output_accuracy: 0.9703 - val_pos_output_loss: 0.0889\n",
            "Epoch 2/10\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.1417 - ner_output_accuracy: 0.9748 - ner_output_loss: 0.0798 - pos_output_accuracy: 0.9776 - pos_output_loss: 0.0619 - val_loss: 0.1705 - val_ner_output_accuracy: 0.9722 - val_ner_output_loss: 0.0920 - val_pos_output_accuracy: 0.9745 - val_pos_output_loss: 0.0785\n",
            "Epoch 3/10\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.1027 - ner_output_accuracy: 0.9802 - ner_output_loss: 0.0596 - pos_output_accuracy: 0.9842 - pos_output_loss: 0.0432 - val_loss: 0.1607 - val_ner_output_accuracy: 0.9740 - val_ner_output_loss: 0.0885 - val_pos_output_accuracy: 0.9772 - val_pos_output_loss: 0.0723\n",
            "Epoch 4/10\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0767 - ner_output_accuracy: 0.9844 - ner_output_loss: 0.0459 - pos_output_accuracy: 0.9890 - pos_output_loss: 0.0308 - val_loss: 0.1628 - val_ner_output_accuracy: 0.9749 - val_ner_output_loss: 0.0898 - val_pos_output_accuracy: 0.9785 - val_pos_output_loss: 0.0730\n",
            "Epoch 5/10\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0578 - ner_output_accuracy: 0.9875 - ner_output_loss: 0.0362 - pos_output_accuracy: 0.9924 - pos_output_loss: 0.0215 - val_loss: 0.1720 - val_ner_output_accuracy: 0.9751 - val_ner_output_loss: 0.0931 - val_pos_output_accuracy: 0.9786 - val_pos_output_loss: 0.0789\n",
            "Epoch 6/10\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0418 - ner_output_accuracy: 0.9908 - ner_output_loss: 0.0269 - pos_output_accuracy: 0.9948 - pos_output_loss: 0.0149 - val_loss: 0.1869 - val_ner_output_accuracy: 0.9751 - val_ner_output_loss: 0.1017 - val_pos_output_accuracy: 0.9779 - val_pos_output_loss: 0.0852\n",
            "Epoch 7/10\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0299 - ner_output_accuracy: 0.9931 - ner_output_loss: 0.0199 - pos_output_accuracy: 0.9967 - pos_output_loss: 0.0100 - val_loss: 0.2064 - val_ner_output_accuracy: 0.9747 - val_ner_output_loss: 0.1125 - val_pos_output_accuracy: 0.9782 - val_pos_output_loss: 0.0939\n",
            "Epoch 8/10\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0211 - ner_output_accuracy: 0.9952 - ner_output_loss: 0.0144 - pos_output_accuracy: 0.9978 - pos_output_loss: 0.0067 - val_loss: 0.2261 - val_ner_output_accuracy: 0.9744 - val_ner_output_loss: 0.1239 - val_pos_output_accuracy: 0.9788 - val_pos_output_loss: 0.1022\n",
            "Epoch 9/10\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0143 - ner_output_accuracy: 0.9967 - ner_output_loss: 0.0099 - pos_output_accuracy: 0.9986 - pos_output_loss: 0.0044 - val_loss: 0.2467 - val_ner_output_accuracy: 0.9739 - val_ner_output_loss: 0.1351 - val_pos_output_accuracy: 0.9783 - val_pos_output_loss: 0.1116\n",
            "Epoch 10/10\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0101 - ner_output_accuracy: 0.9977 - ner_output_loss: 0.0072 - pos_output_accuracy: 0.9991 - pos_output_loss: 0.0029 - val_loss: 0.2700 - val_ner_output_accuracy: 0.9737 - val_ner_output_loss: 0.1494 - val_pos_output_accuracy: 0.9784 - val_pos_output_loss: 0.1206\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7938f2f37650>"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Proqnozları al\n",
        "pred_ner_probs, pred_pos_probs = model.predict(valid_dataset)\n",
        "\n",
        "# Argmax ilə ən yüksək ehtimallı etiketləri seç\n",
        "pred_ner_labels = np.argmax(pred_ner_probs, axis=-1)\n",
        "pred_pos_labels = np.argmax(pred_pos_probs, axis=-1)\n",
        "\n",
        "# İlk 2 nümunəni göstər\n",
        "for i in range(2):\n",
        "    print(f\"\\nExample {i+1}\")\n",
        "    print(f\"{'Token':15} {'True NER':10} {'Pred NER':10} {'True POS':10} {'Pred POS':10}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    input_ids = X_test[i]\n",
        "    true_ner_ids = y_ner_test[i]\n",
        "    pred_ner_ids = pred_ner_labels[i]\n",
        "    true_pos_ids = y_pos_test[i]\n",
        "    pred_pos_ids = pred_pos_labels[i]\n",
        "\n",
        "    for token_id, true_ner_id, pred_ner_id, true_pos_id, pred_pos_id in zip(input_ids, true_ner_ids, pred_ner_ids, true_pos_ids, pred_pos_ids):\n",
        "        if token_id != 0:  # padding tokenləri atla\n",
        "            token = [k for k, v in vocab.items() if v == token_id][0]\n",
        "            true_ner_tag = id2tag[true_ner_id]\n",
        "            pred_ner_tag = id2tag[pred_ner_id]\n",
        "            true_pos_tag = id2pos[true_pos_id]\n",
        "            pred_pos_tag = id2pos[pred_pos_id]\n",
        "\n",
        "            print(f\"{token:15} {true_ner_tag:10} {pred_ner_tag:10} {true_pos_tag:10} {pred_pos_tag:10}\")\n"
      ],
      "metadata": {
        "id": "S8KfcbrPznKL",
        "outputId": "0b4bd82b-73ef-4857-bb0b-e0b6f378083c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\n",
            "Example 1\n",
            "Token           True NER   Pred NER   True POS   Pred POS  \n",
            "------------------------------------------------------------\n",
            "The             O          O          DT         DT        \n",
            "report          O          O          NN         NN        \n",
            "calls           O          O          VBZ        VBZ       \n",
            "on              O          O          IN         IN        \n",
            "President       B-per      B-per      NNP        NNP       \n",
            "Bush            I-per      I-per      NNP        NNP       \n",
            "and             O          O          CC         CC        \n",
            "Congress        B-org      B-org      NNP        NNP       \n",
            "to              O          O          TO         TO        \n",
            "urge            O          O          VB         VB        \n",
            "Chinese         B-gpe      B-gpe      JJ         JJ        \n",
            "officials       O          O          NNS        NNS       \n",
            "not             O          O          RB         RB        \n",
            "to              O          O          TO         TO        \n",
            "use             O          O          VB         VB        \n",
            "the             O          O          DT         DT        \n",
            "global          O          O          JJ         JJ        \n",
            "war             O          O          NN         NN        \n",
            "against         O          O          IN         IN        \n",
            "terrorism       O          O          NN         NN        \n",
            "as              O          O          IN         IN        \n",
            "a               O          O          DT         DT        \n",
            "pretext         O          O          NN         NN        \n",
            "to              O          O          TO         TO        \n",
            "suppress        O          O          VB         VB        \n",
            "minorities      O          O          NNS        NNS       \n",
            "'               O          O          POS        POS       \n",
            "rights          O          O          NNS        NNS       \n",
            ".               O          O          .          .         \n",
            "\n",
            "Example 2\n",
            "Token           True NER   Pred NER   True POS   Pred POS  \n",
            "------------------------------------------------------------\n",
            "the             O          O          DT         DT        \n",
            "Kars-Akhalkalaki B-org      B-per      NNP        NNP       \n",
            "Railroad        I-org      O          NNP        VBG       \n",
            "are             O          O          VBP        VBP       \n",
            "part            O          O          NN         NN        \n",
            "of              O          O          IN         IN        \n",
            "a               O          O          DT         DT        \n",
            "strategy        O          O          NN         NN        \n",
            "to              O          O          TO         TO        \n",
            "capitalize      O          O          VB         VB        \n",
            "on              O          O          IN         IN        \n",
            "Georgia         B-geo      B-geo      NNP        NNP       \n",
            "'s              O          O          POS        POS       \n",
            "strategic       O          O          JJ         JJ        \n",
            "location        O          O          NN         NN        \n",
            "between         O          O          IN         IN        \n",
            "Europe          B-geo      B-geo      NNP        NNP       \n",
            "and             O          O          CC         CC        \n",
            "Asia            B-geo      B-geo      NNP        NNP       \n",
            "and             O          O          CC         CC        \n",
            "develop         O          O          VB         VB        \n",
            "its             O          O          PRP$       PRP$      \n",
            "role            O          O          NN         NN        \n",
            "as              O          O          IN         IN        \n",
            "a               O          O          DT         DT        \n",
            "transit         O          O          NN         NN        \n",
            "point           O          O          NN         NN        \n",
            "for             O          O          IN         IN        \n",
            "gas             O          O          NN         NN        \n",
            ",               O          O          ,          ,         \n",
            "oil             O          O          NN         NN        \n",
            "and             O          O          CC         CC        \n",
            "other           O          O          JJ         JJ        \n",
            "goods           O          O          NNS        NNS       \n",
            ".               O          O          .          .         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentence(sentence, model, vocab, id2tag, id2pos, MAX_LEN):\n",
        "    # 1. Tokenləşdir (sadə boşluqla ayırma)\n",
        "    tokens = sentence.split()\n",
        "\n",
        "    # 2. Tokenləri id-ə çevir\n",
        "    token_ids = [vocab.get(token, 0) for token in tokens]\n",
        "\n",
        "    # 3. Padding et\n",
        "    input_ids = tf.keras.preprocessing.sequence.pad_sequences([token_ids], maxlen=MAX_LEN, padding='post', value=0)\n",
        "\n",
        "    # 4. Pozisional id hazırla\n",
        "    pos_ids = np.tile(np.arange(MAX_LEN), (1, 1))\n",
        "\n",
        "    # 5. Modeldən proqnoz al\n",
        "    pred_ner_probs, pred_pos_probs = model.predict([input_ids, pos_ids])\n",
        "\n",
        "    # 6. Argmax et\n",
        "    pred_ner = np.argmax(pred_ner_probs, axis=-1)[0]\n",
        "    pred_pos = np.argmax(pred_pos_probs, axis=-1)[0]\n",
        "\n",
        "    # 7. Nəticələri çap et\n",
        "    print(f\"{'Token':15} {'Predicted NER':15} {'Predicted POS'}\")\n",
        "    print(\"-\" * 45)\n",
        "    for i, token in enumerate(tokens):\n",
        "        print(f\"{token:15} {id2tag.get(pred_ner[i], 'O'):15} {id2pos.get(pred_pos[i], 'NN')}\")\n",
        "\n",
        "# Nümunə istifadə:\n",
        "sentence = \"Gloria Steinem works with the National Organization for Women to promote feminism.\"\n",
        "predict_sentence(sentence, model, vocab, id2tag, id2pos, MAX_LEN)\n"
      ],
      "metadata": {
        "id": "1yZDTzrpz1va",
        "outputId": "06f23149-00aa-43a5-c1dd-a17141a2ffa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Token           Predicted NER   Predicted POS\n",
            "---------------------------------------------\n",
            "Gloria          B-per           NNP\n",
            "Steinem         O               NN\n",
            "works           O               VBZ\n",
            "with            O               IN\n",
            "the             O               DT\n",
            "National        B-org           NNP\n",
            "Organization    I-org           NNP\n",
            "for             I-org           IN\n",
            "Women           I-org           NNP\n",
            "to              O               TO\n",
            "promote         O               VB\n",
            "feminism.       O               NN\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "Multi-Task NER/POS.ipynb",
      "authorship_tag": "ABX9TyOaWce9oq2drwIRtJP2mxUP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}