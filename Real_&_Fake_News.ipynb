{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyONEhV71+oXO9ml06Xa/773",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leman-cap13/my_projects/blob/main/Real_%26_Fake_News.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yTxrr0-zYeE"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "9I3IMmsyzhDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download razanaqvi14/real-and-fake-news"
      ],
      "metadata": {
        "id": "VOmVzj31zqHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/real-and-fake-news.zip', 'r')\n",
        "zip_ref.extractall()\n"
      ],
      "metadata": {
        "id": "EHPfBSCdz8FL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "qviq4n3nzuYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "8yp41DK_z0MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_true=pd.read_csv('/content/True.csv')"
      ],
      "metadata": {
        "id": "bFbw07blz4HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fake=pd.read_csv('/content/Fake.csv')"
      ],
      "metadata": {
        "id": "_Su8Crc_0J03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_true"
      ],
      "metadata": {
        "id": "47NU841c0RIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fake"
      ],
      "metadata": {
        "id": "L51vK2Vu0RoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_true.isna().sum()\n"
      ],
      "metadata": {
        "id": "_tvgVKKw0Tsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fake.isna().sum()"
      ],
      "metadata": {
        "id": "c-xkRmQw0uyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hər dataframe-ə label əlavə et:\n",
        "df_true[\"label\"] = 1  # Real news\n",
        "df_fake[\"label\"] = 0  # Fake news"
      ],
      "metadata": {
        "id": "3ZNmbHi19Q3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_true, df_fake], ignore_index=True)"
      ],
      "metadata": {
        "id": "5I5Ak2js0yt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "enTT_O7V0yqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data-ı qarışdır (shuffle):\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "99hiVjaV1vnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "frac=1 – bütün datanı al\n",
        "\n",
        "sample() – random olaraq qarışdır\n",
        "\n",
        "reset_index(drop=True) – indexləri sıfırdan başlat"
      ],
      "metadata": {
        "id": "SsqKVRaG92Fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "ukjn_SRK93HN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"content\"] = df[\"title\"] + \" \" + df[\"text\"] # title ve text ikisinide istifade etmek isteyirem deye birlesdirdim\n",
        "X = df[\"content\"].values\n",
        "y = df[\"label\"].values"
      ],
      "metadata": {
        "id": "Pvg8kdCL94m6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "gZqdKJKH_avI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#indi mene tokenler elde etmek lazimdi bunun ucun AutoTokenizer isledecem\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "model_ckpt = 'distilbert-base-uncased'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = AutoModel.from_pretrained(model_ckpt).to(device)"
      ],
      "metadata": {
        "id": "Mf_lSbGo_tJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding class\n",
        "def get_embedding(text):\n",
        "  inputs=tokenizer(text, return_tensors='pt',truncation=True,padding=True,max_length=512)\n",
        "  inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "  with torch.no_grad():\n",
        "    outputs=model(**inputs)\n",
        "  cls_embedding=outputs.last_hidden_state[:,0,:]\n",
        "  return cls_embedding.squeeze().cpu().numpy()"
      ],
      "metadata": {
        "id": "gqWW4g1NAQd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#embeddinglerini gotur\n",
        "embeddings = []\n",
        "for text in df['content']:\n",
        "    emb = get_embedding(text)\n",
        "    embeddings.append(emb)"
      ],
      "metadata": {
        "id": "8SCoTsRICgD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X i update et\n",
        "X=np.array(embeddings)"
      ],
      "metadata": {
        "id": "XiiKFclgC1Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "7hZuPSx3JXxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y\n"
      ],
      "metadata": {
        "id": "9ihYmGfTJaE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Trian test e bolmek ucun train_test_split istifade etdim\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "hbVWrq8gJn-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_clf=LogisticRegression()\n",
        "lr_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "g6JDLu1_I3yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_clf.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "B49yOnAMJqn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_clf.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "RwGGPPClJszI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_preds, y_true, labels):\n",
        "  cm=confusion_matrix(y_true, y_preds, normalize='true')\n",
        "  fig,ax=plt.subplots(figsize=(6,6))\n",
        "  disp=ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "  disp.plot(cmap='Blues', values_format='.2f', ax=ax, colorbar=False)\n",
        "  plt.title('Normalized confusion matrix')\n",
        "  plt.show()\n",
        "y_preds=lr_clf.predict(X_test)\n",
        "plot_confusion_matrix(y_preds,y_test, labels=['Real', 'Fake'])"
      ],
      "metadata": {
        "id": "flDEhMVBJu59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = df['content'][0]\n",
        "\n",
        "# Yenidən tokenləşdir:\n",
        "inputs = tokenizer(sample_text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "\n",
        "# Token id-ləri geri çevirmək:\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "id": "q11pnaNSKMVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_preds))"
      ],
      "metadata": {
        "id": "31iyNCqqKswg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#fine tuning"
      ],
      "metadata": {
        "id": "wDBfO9SKQID-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fine tuning\n",
        "\n",
        "from transformers import  AutoModelForSequenceClassification\n",
        "num_labels=2\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels).to(device)"
      ],
      "metadata": {
        "id": "0L94K2AGLF0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics hazirlayaq\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "def compute_metrics(pred):\n",
        "  labels=pred.label_ids\n",
        "  preds=pred.predictions.argmax(-1)\n",
        "  f1=f1_score(labels, preds, average='weighted')\n",
        "  acc=accuracy_score(labels, preds)\n",
        "  return {'accuracy': acc, 'f1': f1}"
      ],
      "metadata": {
        "id": "mJ55AgFmLFwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "1bHyvZo8Ma7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "batch_size=64\n",
        "\n",
        "model_name=f'{model_ckpt}-finetuned-fake_true_news'\n",
        "training_args=TrainingArguments(\n",
        "    output_dir=model_name,  #main\n",
        "    num_train_epochs=2,  #main\n",
        "    learning_rate=2e-5,   #main\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy='epoch',\n",
        "    disable_tqdm=False,\n",
        "    push_to_hub=True,\n",
        "    log_level='error'\n",
        ")"
      ],
      "metadata": {
        "id": "HiJbqK3BM-vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df[\"content\"].tolist(),\n",
        "    df[\"label\"].tolist(),\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "SN314h30P-7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "train_dataset = Dataset.from_dict({\n",
        "    \"text\": train_texts,\n",
        "    \"label\": train_labels\n",
        "})\n",
        "\n",
        "val_dataset = Dataset.from_dict({\n",
        "    \"text\": val_texts,\n",
        "    \"label\": val_labels\n",
        "})\n"
      ],
      "metadata": {
        "id": "tMei8JZ2NomT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        example[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=512\n",
        "    )"
      ],
      "metadata": {
        "id": "smaT1s8jPDt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "train_dataset = train_dataset.remove_columns([\"text\"])\n",
        "val_dataset = val_dataset.remove_columns([\"text\"])"
      ],
      "metadata": {
        "id": "BtIs8dnQPJjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer=Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "5DzGFVgXNVfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "r-8zzpR3N5MS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_output=trainer.predict(val_dataset)"
      ],
      "metadata": {
        "id": "CaXz8Fi_OHAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_output"
      ],
      "metadata": {
        "id": "gE7She3RafSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(commit_message='Training completed')"
      ],
      "metadata": {
        "id": "uh7rKVC4as2i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}