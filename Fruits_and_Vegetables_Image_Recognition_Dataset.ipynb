{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuGW5ihwCGLWlb4yBACFha",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leman-cap13/my_projects/blob/main/Fruits_and_Vegetables_Image_Recognition_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdEtKkLXGAj9"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "x5CluYRMG8gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d kritikseth/fruit-and-vegetable-image-recognition"
      ],
      "metadata": {
        "id": "pS5JcGTsGM_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile"
      ],
      "metadata": {
        "id": "bcsTyUtoHBhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "zq8vo0oXHs9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('/content/fruit-and-vegetable-image-recognition.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "metadata": {
        "id": "Gken2pVlHEj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_path='/content/test'\n",
        "train_path='/content/train'\n",
        "valid_path='/content/validation'\n",
        "img_size=(224,224)\n",
        "\n",
        "train_data=tf.keras.preprocessing.image_dataset_from_directory(train_path,\n",
        "                                                               image_size=img_size,\n",
        "                                                               shuffle=True,\n",
        "                                                               label_mode='categorical',\n",
        "                                                               batch_size=32,\n",
        "                                                               crop_to_aspect_ratio=True)\n",
        "\n",
        "test_data=tf.keras.preprocessing.image_dataset_from_directory(test_path,\n",
        "                                                               image_size=img_size,\n",
        "                                                               shuffle=True,\n",
        "                                                               label_mode='categorical',\n",
        "                                                               batch_size=32,\n",
        "                                                               crop_to_aspect_ratio=True)\n",
        "\n",
        "valid_data=tf.keras.preprocessing.image_dataset_from_directory(valid_path,\n",
        "                                                               image_size=img_size,\n",
        "                                                               shuffle=True,\n",
        "                                                               label_mode='categorical',\n",
        "                                                               batch_size=32,\n",
        "                                                               crop_to_aspect_ratio=True)"
      ],
      "metadata": {
        "id": "LqoC0n0CHN0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "zkJxvuP9I2Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=train_data.class_names"
      ],
      "metadata": {
        "id": "AAdQmSOfJxQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for image,label in train_data.take(1):\n",
        "  for i in range(12):\n",
        "    plt.subplot(3,4,i+1)\n",
        "    plt.imshow(image[i].numpy().astype('uint8'))\n",
        "    plt.title(class_names[label[i].numpy().argmax()])\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "sh6dwdNrJE-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from functools import partial\n",
        "\n",
        "# Conv2D=partial(tf.keras.layers.Conv2D,\n",
        "#                kernel_size=7,\n",
        "#                filters=32,\n",
        "#                padding='same',\n",
        "#                activation='relu',\n",
        "#                kernel_initializer='he_normal',\n",
        "#                strides=2\n",
        "#                )"
      ],
      "metadata": {
        "id": "pDAz8VRIKcV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = len(train_data.class_names)"
      ],
      "metadata": {
        "id": "En3xomNnNKCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model=tf.keras.Sequential([\n",
        "#     tf.keras.layers.Input(shape=(224,224,3)),\n",
        "#     tf.keras.layers.Rescaling(1/255.),\n",
        "#     Conv2D(),\n",
        "#     tf.keras.layers.MaxPool2D(),\n",
        "#     Conv2D(filters=64,kernel_size=3),\n",
        "#     Conv2D(filters=128, kernel_size=3),\n",
        "#     tf.keras.layers.MaxPool2D(),\n",
        "#     Conv2D(filters=256,kernel_size=3),\n",
        "#     Conv2D(filters=512, kernel_size=3),\n",
        "#     tf.keras.layers.MaxPool2D(),\n",
        "#     tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
        "#     tf.keras.layers.Dense(64, activation='relu', kernel_initializer='he_normal'),\n",
        "#     tf.keras.layers.BatchNormalization(),\n",
        "#     tf.keras.layers.Dense(n_classes, activation='softmax')\n",
        "\n",
        "\n",
        "# ])"
      ],
      "metadata": {
        "id": "QGCE7BSSKGlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer = tf.keras.optimizers.Nadam(),\n",
        "#               metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jrSJr8jpNvhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit(train_data, validation_data=valid_data, epochs=3)"
      ],
      "metadata": {
        "id": "WuXB_guJOPCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=tf.keras.layers.Input(shape=(224,224,3))\n",
        "\n",
        "x=tf.keras.applications.xception.preprocess_input(inputs)\n",
        "\n",
        "base_model=tf.keras.applications.Xception(weights='imagenet', include_top=False,input_tensor=x)\n",
        "base_model.trainable=True\n",
        "for layer in base_model.layers[100:]:\n",
        "  layer.trainable=False\n",
        "\n",
        "avg_pool = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "\n",
        "x=tf.keras.layers.Dense(128,activation='relu', kernel_initializer='he_normal')(avg_pool)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "output = tf.keras.layers.Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "model=tf.keras.Model(inputs,output)\n"
      ],
      "metadata": {
        "id": "4hCdvCc7UeLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = tf.keras.optimizers.Nadam(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Pok9htOLBq3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data, validation_data=valid_data, epochs=3)"
      ],
      "metadata": {
        "id": "aBhmxb7iBteY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}